## 제8장 내비게이션: 티맵은 어떻게 가장 빠른 길을 알까

```
< Discussion >

불필요한 가정을 배제하고, 간단한 것을 택하라는 '오컴의 면도날'이 8장에서 반복해서 등장합니다.

일상에서 ‘단순함이 복잡함을 이겼던' 경험, 또는 단순한 방법이 오히려 더 효과적일 것 같은 상황이나 사고 방식에 대해 얘기해 보고 싶습니다.
```

#### 내비게이션, 당신의 스마트한 운전 비서

- 현재의 내비게이션을 사용할 수 있기까지 2가지 터닝 포인트가 있다.
  1. 미국이 더욱 정확한 GPS 위성을 쏘아 올렸다.
  - 미국은 1970년대에 군사적 목적으로 24개의 GPS 위성을 쏘아 올렸지만 적대국도 사용할 수 있다는 우려에 일부러 100m 이상 오차를 발생시켰다. 2000년 클린턴 정부 때 이 오차를 없애면서 민간에서도 정확도 높은 GPS 신호를 마음껏 사용할 수 있게 되었다.
  2. 내비게이션 시스템이 교통정보와 머신러닝까지 연동되었다.
  - 단순히 지도 정보와 현재 위치를 표출해주던 초창기 내비게이션이 실시간 교통정보와 연동되면서 최적의 경로를 안내할 수 있게 되었다. 또한 머신러닝 탑재로 정체 구간, 최적 출발 시간 등을 예측하면서 편의성을 대폭 키웠다.
- 내비게이션은 자율주행차 운행에서도 매우 중요하다. 정교한 지도를 기반으로 현재 위치를 파악하는 일은 자율주행차 주행의 핵심이다.
- 지도는 도로 상황의 변화를 빠르게 반영해야 하므로 국내 상황에 익숙지 않은 해외 업체가 국내에 진출하기 어렵다.

#### 오컴의 면도날 법칙

> `오컴의 면도날(Occam's Razor)`<br/>
> 면도날로 도려내듯 단순한 모델이 최선이라는 원칙. 흔히 '경제성의 원리', '단순성의 원리'로 불리며, "필요 이상으로 많은 것을 가정하지 말라"는 라틴어 문구에서 유래됐다.

- 모든 모델은 잘못됐다. 그러나 일부는 유용하다.
  - 어떤 모델도 현실 세계를 완벽하게 기술하지는 못한다.
- 크고 복잡한 모델이 항상 좋은 것만은 아니다.

#### 예측을 좌우하는 데이터

- 불완전하거나 제한된 학습 데이터에 지나치게 특화되어 새로운 샘플에 대한 예측 결과가 오히려 나빠지거나 학습 효과가 나타나지 않는 데이터 과적합 문제에 유의해야 한다.
- 제대로 예측하기 위해서는 학습 데이터가 균형 있게 구성되어야 한다. 또는 불균형을 해결해줄 특별한 알고리즘이 필요하다.
- 알고리즘이 인간의 편견을 학습하지 않도록 데이터 편향(Bias)도 항상 예의 주시해야 한다.

#### 의사결정나무, 단순한 모델의 힘

> 의사결정나무(Decision Tree)<br/>
> 스무고개 놀이와 같이 조건에 따라 분기하는 모델

- 의사결정나무를 구축할 때는 복잡도인 엔트로피(Entropy)를 낮추는 형태로 진행한다. 복잡도는 불확실성의 정도라 할 수 있다.
  - 즉, 엔트로피가 낮아지면 복잡도와 불확실성이 줄어든다. 의사결정나무는 엔트로피를 낮춰 덜 복잡하게(= 불확실하게) 하여 가급적 정답을 빨리 맞히는 것이다.
- 의사결정나무는 판별 과정이 투명하게 보이므로 왜 그렇게 판단했는지 금방 이유를 알 수 있다. 해석이 쉬운 단순한 모델은 어려운 딥러닝에 비해 오류를 쉽게 발견하고 수정할 수 있는 장점이 있다.
- 하지만 의사결정나무는 단 한 번의 오류에도 취약한 모델이다. 따라서 온갖 오류가 넘치는 현실의 데이터로는 정확도를 높이기 어렵다.

#### 랜덤 포레스트, 대중의 지혜를 발휘하다

- 버클리대학교의 통계학자 레오 브라이만은 2001년 오류에 견고한 새로운 모델 `랜덤 포레스트`\*를 제안했다.
  > \* `랜덤 포레스트(Random Forest)`<br/>
  > 데이터와 특징에 제한을 두고 샘플을 추출한 다음, 여러 개의 의사결정나무를 만들어 각각의 결과를 두고 투표해 최종 결과를 정하는 방식
- 각각의 의사결정나무는 데이터와 특징을 제안하므로 단일 의사결정나무에 비해 성능이 훨씬 더 떨어진다.
  - 그러나 이런 의사결정나무가 늘어나게 되면 '대중의 지혜'와 같은 엄청난 위력을 발휘한다. 데이터의 오류 등으로 일부 의사결정나무가 잘못된 결과를 내리더라도 나머지 나무들이 올바른 결과를 낼 수 있기 때문에 전체적으로는 오차에 매우 견고해진다.
- 랜덤 포레스트는 마이크로소프트의 게임기인 엑스박스의 모션센서가 사람의 동작을 판별하는 데 사용한 알고리즘으로도 유명하다.

#### 그레이디언트 부스팅, 정답과 거리를 줄여나가다

> 잔차(Residual)<br/>
> 통계학 개념으로, 오차(Error)와 비슷한 개념인데 잔차는 전체에 대한 오차가 아니라 샘플의 오차라는 차이가 있다. 오차보다는 훨씬 더 작은 개념으로, 잔차를 줄여나가면 모델을 훨씬 더 정교하게 개선할 수 있으므로 통계학에서 여러 모델을 만드는 데 중요하게 쓰인다.
> <br/>  
> 그레이디언트 부스팅(Gradient Boosting)<br/>
> 먼저 의사결정나무를 하나 만든다. 그리고 이 나무에서 오류가 발생하면 실수를 바로 잡는 새로운 나무를 만든다. 이 과정을 오류가 최소화할 때까지 반복하며 잔차를 계속해서 줄여나가는 방식

- 그레이디언트 부스팅 모델은 랜덤 포레스트보다 훨씬 더 성능이 뛰어나다. 심지어 그레이디언트 부스팅을 응용한 모델은 딥러닝보다 더 뛰어난 성능을 보이며 여러 분야에 활발히 활용되고 있다.

#### 데이크스트라 알고리즘, 최단 거리 탐색의 비밀

- 최단 경로를 찾는 알고리즘 중 가장 유명한 것은 `데이크스트라(Dijkstra's) 알고리즘` 일 것이다. 네덜란드의 컴퓨터 과학자 에츠허르 데이크스트라가 대학원생이던 1956년에 여자친구와 함께 카페에 갔다가 20분 만에 고안했다.
  - 카페에서 냅킨에 적을 수 있을 만큼 단순한 법칙으로, 단순한 법칙이 가장 뛰어나다는 오컴의 면도날을 증명하는 대표적인 알고리즘이다.
- 데이크스트라 알고리즘은 현재 위치에서 주변을 모두 살핀 후 그 중 항상 최단 경로를 택하는 알고리즘이다. 단순할 뿐만 아니라, 찾는 속도도 매우 빠르다.
- 그러나 데이크스트라 알고리즘은 너무 많은 경로를 탐색하기 때문에, 최적 경로를 탐색하는데 너무 오랜 시간이 걸린다는 문제가 있다.

#### 모든 내비게이션이 채택한 A\* 알고리즘

- 1968년에 스탠퍼드 연구소(SRI)에서 `A* 알고리즘`을 개발했다. ('에이스타' 라고 읽는다)
  - 스탠퍼드 연구소는 이후 1970년에 스탠퍼드대학교에서 분리되어 1977년부터는 SRI 인터네셔널을 공식 명칭으로 사용한다. 시리를 만든 그 곳
- A\* 알고리즘은 데이크스트라 알고리즘의 확장판으로 볼 수 있는데, 거의 모든 경로를 탐색하던 데이크스트라에 비해 꼭 필요한 경로만 탐색하여 탐색 횟수를 대폭 줄였다.
  - 출발지에서 도착지로 이동하는 시간뿐 아니라 도착지에서 출발지로 거꾸로 이동하는 시간도 함께 계산에 포함하여 양방향 경로 탐색을 통해 최적 경로를 찾아내는 방식이다. 이렇게 하면 도착지에서 먼 곳은 탐색할 시도조차 하지 않게 된다.
- A* 알고리즘에는 다양한 변수를 적용할 수 있기 때문에 활용도가 매우 높다. 사실상 시중에 있는 모든 내비게이션은 A* 알고리즘을 응용해 최적 경로를 계산한다.

#### 내비게이션, 경로 안내 그 이상의 것

- 새로 만든 도로에 차량들이 몰리면 교통 정체 상황이 도로 개통 이전보다 더욱 악화되는 경우가 있는데, 교통 분야에서는 이를 `브라에스 역설(Braess Paradox)` 라고 한다.
- 교통 시설 전체를 효율적으로 활용하려면 시간과 공간에 차량이 적절히 분포되어야 한다. 따라서 내비게이션은 모든 차량에 동일한 최적 경로를 제공하기보다 우회 경로를 포함한 다양한 경로를 제시할 필요가 있다.
  - 물론 내비게이션이 전체 교통 상황을 고려해 특정 사용자에게 최적이 아닌 경로를 강제해도 되는지에 관해서는 여전히 논란의 소지가 있다.

---

#### Comment

- (p.391) 브라이만은 73세에 가장 위대한 업적을 남겼다. 모든 사람은 자기만의 시간이 있다.
- (p.398) 도착지에서 출발지로의 경로를 거꾸로 탐색하면 탐색 횟수가 줄어든다는 내용 이해가 어려웠다. 거꾸로 탐색하는 기준이 어디까지인지, 왜 탐색 횟수가 줄어드는지 조금 더 디테일하게 설명해주면 좋았을 텐데.
  - 성남 → 복정 구간을 딱 한 번만 살펴본다고 했는데, 이 구간도 4가지의 방법이 있는데? 4가지 방법을 딱 한 번 살펴본다는 건가?
