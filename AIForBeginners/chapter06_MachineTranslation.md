## 제6장 기계번역: 외국어를 몰라도 파파고만 있다면

```
< Discussion >
기계 번역과 인간 번역의 차이는? 기계 번역의 정확도가 월등히 높아지고 있는 상황에서 사람이 직접 번역하는 작업의 차별성은 어디에 있을까요?

관련해서 정보를 찾아보다가 관련 내용을 잘 정리해놓은 글이 있어 아래에 링크 첨부합니다. 특히, 이 이슈에 있어 고민이 가장 클 수 있는 한국외대 재학생들의 포스팅이라 더욱 흥미롭네요.

https://blog.naver.com/hufsjournal/223754473934
```

#### 위대한 인공지능, 깨어나다

- 구글 번역이 인공 신경망을 도입하면서 하루 사이에 번역 품질이 획기적으로 개선되었다. 이를 알아챈 도쿄대학교의 레키모토 준이치 교수를 통해 해당 이슈가 일본에서 회자되었다.

#### 인간의 언어가 정말 어려운 이유

1. 너무 많은 규칙

- 인간의 언어를 몇 가지 규칙만으로 설명하기란 사실상 불가능하다. 신조어가 생겨나면서 계속 확장하기 때문. 언어는 살아 움직이는 생명체처럼 끊임없이 진화한다.
- 언어는 특정한 규칙을 따라 과학적인 방식으로 발전하지 않는다. 세월의 흔적이 인간의 언어에 반영된다.

2. 너무 많은 오류

- 모든 사람이 문법에 맞게 말하면 좋겠지만 일상적인 대화에는 무수히 많은 문법적 오류가 있다. 그럼에도, 우리의 뇌는 웬만한 오류를 보정하고 이해한다.

3. 너무 많은 의미

- 같은 발음을 지닌 단어가 여러 뜻을 같는 경우가 많다. 앞뒤 문장과 전체적인 맥락을 살펴봐야 해당 단어의 의미를 알 수 있다.

#### 기계번역의 시작

> `기계번역(Machine Translation)`<br/>
> 인간이 사용하는 언어를 기계를 이용해 다른 언어로 번역해내는 일

- 기계번역이라는 용어는 1949년부터 논문에 등장, 1950년대에는 MIT를 비롯한 여러 대학에서 연구하기 시작했다. 1954년에는 조지타운대학교와 IBM이 공동으로 러시아어를 영어로 번역하는 공개 시연회를 진행했다.

#### 규칙 기반, 모든 규칙을 정의하다

- 기계번역을 대표하는 회사로, 1968년 설립된 `시스트란(SYSTRAN)`은 2000년대 초반까지는 야후!와 구글에 제품을 납품할 정도로 세계 최고의 번역 품질을 자랑했다. 시스트란은 규칙 기반 기계번역을 이용했다. 하지만 쉽게 예상할 수 있듯 규칙 기반에는 한계가 있었다.

#### 예시 기반과 통계 기반, 가능성을 보이다

- 1980년대 교토대학교의 `나가오 마코토` 교수는 `예시 기반 기계번역` 방식을 제안했다.
  - 기존의 규칙 기반 번역 대신 풍부한 데이터를 활용해 문장 전체의 맥락을 살펴보는 데 주안점을 두었다. 즉, 규칙을 통해 언어를 '이해'하기보다, 경험을 통해 '모방'하는 형태로 접근했다.
- 1990년대에는 기존의 규칙 기반이나 예시 기반을 뛰어넘는 본격적인 번역 모델로서 `통계 기반 기계번역`이 등장했다.
  - 이 모델은 문장을 단어 또는 구문 단위로 분할한 다음 이를 번역하고 다시 합치는 과정에 확률적인 방법을 접목했다.
- 언어학자가 더 이상 규칙을 만들 필요가 없고, 오히려 규칙을 없앨수록 더 자연스러운 문장을 만들어낼 수 있게 되었다.
  > 언어학자를 해고할 때마다 성능은 높아진다.  
  > \- Frederic Jelinek, IBM의 과학자

#### 인공 신경망 기반, 마침내 혁신이 시작되다

- 2010년대에는 문장 전체에 딥러닝을 적용한 `신경망 기반 기계번역`이 등장했다. 여기에는 우리나라의 `조경현` 교수가 몬트리올대학교에서 박사 후 과정 중에 기여한 바도 크다.
- 신경망은 문장을 통째로 압축해 숫자로 표현한 벡터(방향과 크기를 나타내는 값)를 만든다. 그리고 벡터 값을 번역할 언어로 옮긴 다음 풀어서 번역문을 만들어낸다. 각 숫자에서 가장 확률이 높은 번역문을 찾아내는 것이다.

#### 어텐션, 가장 혁신적인 발명

> `인코더(Encoder)` : 문장을 압축하는 부분

- 문장을 압축하는 과정 : 문장을 띄어쓰기 단위로 구분 - 차례대로 인공 신경망을 통과하며 핵심적인 특징을 추출 - 여러 번의 계산을 거쳐 최대한 압축하면 마지막 단계에서 문장 전체의 의미를 압축한 벡터가 생성됨

> `디코더(Encoder)` : 문장을 푸는 부분

- 문장을 푸는 과정 : 1 앞선 단어의 번역과 2 인코더가 압축한 벡터, 두 가지 입력을 받아 한 단어씩 순서대로 풀어내며 출력 문장 생성

- 그러나 이 방식에는 2가지 문제가 있었다.
  1. 번역할 원문의 길이와 관계없이 원문을 일정한 길이의 벡터로 한 번만 압축
  2. 한 번 만든 벡터를 계속 참조하다보니 번역문이 길어질수록 핵심 단어를 놓침
- 2014년 조경현 교수가 제2저자로 출판한 논문에서 이 문제들의 한계를 극복하는 혁신적 개념인 `어텐션(Attention)`을 제안했다. 더 중요한 단어에 '주목'한다는 간단한 원리다.
  - 어텐션은 번역문의 단어를 생성할 때마다 출력 문장의 길이에 맞춰 압축 벡터를 생성한다. 이렇게 하면 번역문이 길어질수록 벡터도 함께 길어지므로 긴 문장을 번역하는데 문제가 없다.
  - 어텐션의 핵심은 중요한 단어에 별도 가중치를 부여할 수 있다는 점이다. 이전에는 아무 표시 없이 문장 전체를 통째로 압축해서 번역 시 어떤 단어를 염두에 두어야 하는지 알 수 없었으나, 어텐션은 압축할 때 매번 다르게 중요한 부분을 표시해둘 수 있다.
- 어텐션은 기계번역의 성능을 크게 높였다. 기계번역의 성능을 보조하는 역할로 처음 등장했으나 이제는 기계번역의 핵심이 되었다.
  - 어텐션을 핵심 알고리즘으로 삼은 `트랜스포머(Transformer)` 모델은 사실상 모든 기계번역 모델을 대체했다.

#### 인간을 뛰어넘은 기계번역

- 구글은 2006년 통계 기반 기계번역 서비스 출시 이후 꾸준히 번역기의 성능을 높여왔다. 유엔과 유럽 의회의 회의록을 데이터로 활용했다.
  - 2016년 인공 신경망 기반 번역 서비스를 출시하고, 현재는 109개 언어의 번역을 지원하는 세계 최대 규모의 번역 서비스로 성장했다.
- 2017년에는 카카오가 챗봇 형태의 카카오 i 번역 서비스를 출시했다.
  - 검색엔진 개발 팀장이자 기계번역 분야 석사학위를 받았던 직원의 사이드 프로젝트가 정식 서비스로 확대되어 출시된 것이다.
- 파파고는 세계 최초의 신경망 기반 영어-한국어 기계번역 서비스다.
  - 파파고를 개발한 핵심 인력들은 이후 현대자동차에서 자동차 도메인에 적합하도록 모델을 개선하여 신경망 기반의 사내 번역 서비스를 출시했다.

---

#### Comment

- (p.251) 1장의 제목으로도 쓰였던 '위대한 인공지능, 깨어나다' 타이틀이 6장의 소제목으로도 쓰였다. 한 책에서 타이틀로 여러 번 등장하는 것을 보니 동명의 뉴욕 타임스 기사가 인공지능 분야에서는 꽤 큰 영향이 있었나보다.
- (p.268) 신경망 기반 기계번역 방식이 문장을 통째로 한 번에 번역해 단순하다지만, 오히려 단순해서 글로는 전혀 이해가 안 된다. 문장 압축 - 벡터 생성 - 확률이 높은 번역문 추출 ..?
- (p.283) 파파고가 앵무새란 뜻이었구나. 에스페란토어는 또 뭐람. 세계에서 가장 많이 쓰이는 인공어란다 😮
  - [참고] https://m.blog.naver.com/mofakr/222427134914
- (p.283-284) 찾아보니, 현대자동차 사내 번역 서비스 이름은 `H-트랜스레이터`라고 한다. 들어본 적이 있는 듯.
  - [참고] https://www.hyundai.co.kr/story/CONT0000000000001578
- 책을 반 이상 쯤 읽고 보니, 이 책에 등장하는 많은 기술 용어, 사람 이름, 기관명을 어떤 방식으로 받아들이면서 읽어야 하는지에 대해 약간 고민이 된다.
