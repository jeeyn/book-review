## 제7장 챗봇: 챗GPT, 1분 안에 보고서 작성해 줘

### Section 2

```
< Discussion >

(p.341) 언어 모델의 학습 데이터로 인간의 피드백을 이용하기 때문에, 인간과 마찬가지로 생성 모델도 한 번 편견에 빠지기 시작하면 계속해서 편견에 빠진다는 부분이 인상 깊었습니다.

관련해서 AI 윤리에 대한 이야기를 해보면 어떨까요?
완전히 공정한 인공지능 개발이 가능할까? 사회적으로 공정하고 안전한 AI 개발은 누가 책임져야 할까요?

그 과정에서는 편향되지 않은 학습 데이터에 대한 기준도 제시되어야 할텐데 이 기준은 어떻게 세워야 하며, 기업이 이를 어디까지 따라야 할까요?

[참고] https://modulabs.co.kr/blog/ai-ethics
[참고] https://www.ncfoundation.or.kr/main
```

#### GPT-3, 인간을 능가하는 언어 생성 모델

- 2015년, 인류 전체에 이익이 되는 범용 인공지능을 목표로 비영리 인공지능연구소 오픈AI가 발족했다.
  - 일론 머스크가 설립하고, 실리콘 밸리 투자 회사 Y컴비네이터의 회장을 역임한 샘 올트먼이 대표를 맡았다.
  - 마이크로소프트가 한화 약 18조원 가까이 투자하면서 오픈AI의 지분 49%를 보유해 화제가 되기도 했다.
- 오픈AI의 대표적인 결과물은 언어 생성 모델인 `GPT(Generative Pretrained Transformer)` 이다.
  - GPT 언어 모델은 문장의 다음 단어가 무엇이 나올지 맞추도록 학습한다.
- GPT가 처음 공개됐을 때는 그리 주목받지 못했다. 이미 비슷한 언어 모델은 많이 나와 있었고, 이에 비해 두드러진 성능을 보여주지 못 했기 때문이다.
- 2번째 버전인 GPT-2는 GPT 보다 10배 이상 컸다. 모델의 크기를 키우고 학습 데이터를 늘리자 마치 사람이 글을 직접 쓴 것처럼 성능이 매우 좋아졌다.
  - 이 때문에 스팸, 가짜뉴스 등을 쏟아낼 우려가 있었고, 오픈AI는 이 모델을 공개하지 않기로 결정했다.
- 이듬해 공개된 GPT-3는 GPT-2 보다도 100배 큰 모델이었다.
  - 오픈AI는 GPT-3를 유료 API로 제공하기로 결정했고, 소스코드에 접근할 권한은 마이크로소프트에 독점적으로 부여했다.
- 오픈AI는 공개하지 않겠다던 GPT-2 전체 모델을 2019년 11월에 공개했다. GPT-2가 공개되면 스팸과 가짜뉴스를 양산해 사회가 혼란에 빠질 것이라는 우려와는 달리 공개 이후 아무런 일도 일어나지 않았다.
- 2020년 9월부터는 GPT-3의 유료 서비스를 개시했다.
- 비영리로 운영하던 오픈AI는 제한적 영리추구 법인을 별도로 설립했다.
- GPT 시리즈의 성공에 힘입어 국내에서도 언어 생성 모델을 구축하려는 시도가 잇따르고 있다. 대표적으로 네이버에서 구축한 `하이퍼클로바(HyperCLOVA)`가 있다.

#### 구글과 페이스북의 챗봇이 등장하다

- GPT-2를 이용한 언어 생성 모델이 가능성을 보여준 이후, 그 근간이 되는 트랜스포머 모델을 기반으로 다양한 챗봇이 등장했다. 대표적으로 `구글 미나(Meena)`가 있다
  - 26억 개의 매개변수 사용, 341GB의 텍스트 데이터를 학습했다.
- 이후 2020년 4월에는 페이스북에서 `블렌더 봇(Blender Bot)`을 공개했다.
  - 94억 개의 매개변수 사용, 15억 건의 대화를 학습했다.

#### 챗GPT, 챗봇 끝판왕의 등장

- GPT-3가 아무리 초거대 모델이라고 해도 그다음에 나올 단어가 무엇인지 예측하는 단순 확률 모델에 불과하다. 즉, 사용자 프롬프트를 잘 따르도록 설계한 모델은 아니었다.
- 오픈AI는 2년여의 추가 연구 끝에 GPT-3가 사용자 프롬프트(사람이 지시하는 내용)를 잘 따르도록 튜닝한 모델인 `Instruct GPT`를 만들어냈고, 이후 자사의 API를 모두 인스트럭스GPT 기반으로 업데이트했다.
- 인스트럭트GPT는 사용자 프롬프트를 잘 따를 수 있도록 3단계 과정을 거쳐 GPT-3를 업그레이드 한 모델이다.
  - 1단계 : 데이터셋을 구축해 지도 미세 조정(Supervised Fine-Tuning) 모델을 학습하는 단계. SFT 모델은 인간이 세심하게 정제한 '좋은' 데이터를 넣고 더 다듬은 모델이다.
  - 2단계 : 비교 데이터를 구축하고 보상 모델(Reward Model)을 학습하는 단계. RM 모델은 하나의 질문에 여러 답변을 두고 어떤 답변이 만족스러운지 순위를 매기는 과정을 거친다.
  - 3단계 : 강화학습을 이용해 성능을 높이는 단계. RM 모델을 이용해 보상을 최적화하는 단계이며, 이 단계에서는 오픈AI가 이미 2017년에 게임에 적용하기 위해 개발했던 근접 정책 최적화(PPO; Proximal Policy Optimization) 알고리즘을 사용했다.
    - 이 과정은 3단계 중 가장 어렵고 핵심적인 과정이다. PPO 알고리즘을 이용한 보상 과정은 모두 자동으로 진행되며, 끊임없이 스스로 반복하며 학습한다.
- 이 3단계의 기술을 통칭하여 RLHF(Reinforcement Learning from Human Feedback)라 한다. '인간의 피드백을 이용한 강화학습' 이라는 뜻
- 그러나, 인스트럭트GPT는 무슨 말을 할 지 예측 불가(대답의 사실 여부 확인 불가)했고, 차별과 편향을 점점 더 드러냈다.
- 오픈AI는 이 문제를 다음과 같이 보완했다.
  - 데이터 수집 설정을 보완하고 데이터 작업자들을 다양한 인종과 성별로 구성해 최대한 중립을 지키도록 했다.
  - 자연스러운 대화체를 쓸 수 있도록 기존 데이터를 대화 형식으로 바꿔 재학습시켰다.
  - 밑바탕 모델도 한층 업그레이드된 GPT-3.5를 사용했다.
  - 중재 역할을 하는 API를 도입하여 폭력, 자해, 증오, 성적인 내용 등은 사전에 분류하여 제어하고, 공격적 말투나 위험한 내용은 차단, 부적절한 요청은 거부하도록 했다.
  - 잘못된 정보는 사전에 확인하여 팩트 체크를 할 수 있도록 안전 모듈도 강화했다.
- 이러한 과정을 통해 완성한 결과물이 챗GPT이며, 오픈AI는 이 기술을 2022년 11월, 세상에 공개했다.
  - 이후 2023년 2월 초에 월 20달러의 유료 버전 출시, 2023년 2월에는 MS의 검색엔진 빙(Bing)에 도입되었다.
  - 공개 5일 만에 사용자 100만 명, 40일 후에는 1,000만 명을 넘겼으며, 이제 1억 명 이상을 넘겼다.
    - 사용자 100만 명을 넘기는 데 넷플릭스 3.5년, 트위터 2년, 페이스북 10개월, 인스타그램 2.5개월이 걸렸다.
  - 2024년 상반기 기준 전체 유료 사용자는 390만 명을 넘어섰으며, 챗GPT 구독료와 유료 API 서비스에 따른 연간 매출은 34억 달러에 달했다.
- MS가 검색엔진 빙에 챗GPT 연동한 이후 단 1주일 만에 한 해(2021년) 다운로드 수를 넘어섰다.
  - 챗GPT가 빙에 도입된 직후 구글의 주가는 무려 10% 이상 떨어지기도 했다.

#### GPT-4, 마침내 진정한 인공지능의 시대에 다가서다

- 2023년 3월 15일, 오픈AI는 다음 버전 GPT-4를 발표했다.
  - 그동안 GPT는 1년 주기로 새로운 버전을 발표했으나, GPT-4는 GPT-3 이후 3년만에 등장했다.
- 오픈AI는 GPT-4와 관련된 기술을 아무것도 공개하지 않기로 결정했다. 의례 함께 발표하던 연구 논문도 공개하지 않았고, 단지 '기술 보고서' 라는 이름으로 GPT-4가 얼마나 뛰어난 언어 모델인지를 소개하는 내용만 공개했다.
  - 이는 두 가지 의미를 지닌다. 첫 번째로, 이제 언어 모델은 연구 단계를 넘어 제품화 단계에 돌입했다고 볼 수 있다. 본격적으로 플랫폼 비즈니스를 진행할 제품화 단계에 돌입한 것이다.
  - 두 번째로, 연구 성과로 공개할 내용이 많지 않다고 예상할 수도 있다. 새로운 연구를 GPT에 적용했다기 보다는 고품질의 데이터를 사용하고, 안전 모듈을 크게 강화하는 등의 변화가 있을 뿐 근간이 되는 기술은 크게 변하지 않았을 것으로 추정할 수 있다.
    - GPT-4는 논문으로 남길 정도의 새로운 연구 대신 기존 기술을 제품화 하면서 더욱 정교하게 다듬은 과정의 결과라는 것

#### 기계가 언어를 이해할 수 있을까?

> `질의응답(Question answering)`<br/>
> 사용자로부터 받은 특정한 종류의 정보에 대한 질문을 자연어로 받아들여 해답을 주는 기술

- 질의응답은 기계번역과 함께 자연어 처리 연구의 대표적인 난제 중 하나였으나, 최근 딥러닝이 도입되면서 연구가 급물살을 타고 있다.
- 언어를 이해하는 가장 유명한 모델은 구글에서 개발한 `버트(BERT)` 가 있다.
  - GPT가 채택한 것은 트랜스포머의 디코더이고, 버트는 인코더이다. 인코더는 언어의 이해를 담당하고, 디코더는 언어의 생성을 담당한다.
- 버트는 사전 지식을 활용하여 모델의 정확도를 높이는 대표적인 모델이다. 이를 미리 학습한 사전 지식을 그대로 가져와서 `전이 학습(Transfer Learning)` 한다고 말한다.
  - 전이 학습할 경우 엄청난 데이터를 매번 학습할 필요가 없다. 추가 학습을 조금만 해도 충분히 좋은 성능을 낸다.

#### 튜링 테스트와 중국어 방

- 앨런 튜링은 논문 <계산 기계와 지능>에서 '기계는 생각할 수 있는가?'라는 담대한 질문을 던지며 '생각'의 정의를 내리는 어려운 과정을 탐구하는 대신에 인간이 생각한다고 여기는 행동을 기계가 흉내낼 수 있다면 이를 '생각한다'고 판정하자고 제안한다.
  - 이 발상을 바탕으로 제안한 것이 바로 `이미테이션 게임` 이다.
  - 튜링은 이 게임을 '기계는 생각할 수 있는가?' 라는 어려운 질문 대신에 사용하자고 제안했다. 이것이 바로 `튜링 테스트` 이다.
- 튜링 테스트에 대한 대표적인 비판으로 버클리대학교의 존 설 교수가 1980년에 발표한 `중국어 방` 사고 실험이 있다.

#### 인공지능이 진정한 이해를 묻다

- 미래학자 `레이 커즈와일`은 <마음의 탄생> 에서 튜링 테스트만으로 컴퓨터가 인간 수준의 지능을 갖고 있는지 테스트 하기 충분하다는 의견을 피력했다.
  - 커즈와일은 전작 <특이점이 온다> 에서는 특이점(Singularity), 즉 기계가 인간 지능을 추월하는 시점이 오는 시기를 2045년 전후로 예상했다.
- 인디애나대학교의 더글러스 호프스테터 교수는 1979년 출간한 <괴델, 에셔, 바흐> 라는 책에서 인공지능에 대한 비판과 매우 깊이 있는 통찰력을 제시했다.
  - 호프스테터는 인공지능 연구가 인간 의식에 관한 근본적인 질문은 잊어버린 채 온통 기술 중심으로만 개발되고 있는 현실에 불만을 표했다.
    - 공학자들은 지난 몇십 년간 지능을 '만들어내는' 데는 탁월한 성과를 거뒀지만 정작 지능을 '이해하는' 데는 턱없이 부족했다고 비판했다.
    - 의미 있는 인공지능을 만드는 유일한 방법은 인간의 상상력이 작동하는 방식을 이해하는 것이라 믿었다.
- 아쉽게도 호프스테터의 접근 방식은 주류 인공지능 연구와는 많이 달랐고, 21세기 들어 사실상 폐기되다시피 되었다. 이후에는 무어의 법칙으로 대표되는 연산 능력의 발전에 힘입어 계산의 시대가 열렸다.

---

#### Comment

- (p.336-337) 오픈AI가 좋은 데이터를 마련하는데 각별히 신경 쓴 내용이 흥미로웠다. 이와 관련한 내용을 좀 더 읽어보아도 좋을 듯
- (p.346) 마이크로소프트가 오픈AI와 전략적 파트너십을 맺고 있다는 점으로 인해 향후 시장이 어떻게 변할 지 지켜보는 것도 재미있겠다. 검색엔진 분야에서 어떤 변화가 있을지?
- (p.351-358) 트랜스포머에서 인코더를 채택한 언어 모델과 디코더를 채택한 언어 모델의 차이가 명확히 무엇인지 이해하기가 조금 어려웠다. 사용자 입장에서는 질문의 의도를 이해하고 답변을 제공한다는 점에서 같기 때문에. 이 챕터에서 작가가 GPT 설명 이후 이 내용을 이어서 구성(서술)한 것에 대한 의도가 무엇일까 궁금했다.
- (p.365) 인간의 상상력이 작동하는 방식을 이해하는 것이란 무엇일까.
- GPT 공개와 제품화 과정을 보면서 기술(또는 어떤 서비스라도)의 혁신이 일어나려면 충분한 시간과 자본이 반드시 필요함을 한 번 더 깨닫게 되었다. 특히 자본에 앞서 절대적인 시간이 필요하다.
