## 제1장 인간을 능가하는 GPT-4

```
< Discussion >
GPT-4가 공개된 지 벌써 2년 가까운 시간이 되었는데,

챗GPT를 처음 접했을 때와 지금, 개인의 사용 방식이나 태도가 어떻게 달라졌나요?
그리고 챗GPT로 인해 일상에서 체감하는 가장 큰 변화는 무엇인지 얘기해보고 싶습니다.
```

#### 들어가며

- 챗GPT를 필두로 한 인공지능 혁명의 중심에는 현 시대를 새롭게 정의하는 거인들이 있다.
  - 오픈AI의 샘 올트먼, 엔비디아의 젠슨 황, xAI의 일론 머스크, 구글 딥마인드의 데미스 허사비스, 메타의 마크 저커버그는 단순한 기업인을 넘어 21세기의 새로운 패러다임을 형성하며 미래 비전을 제시하는 인물들이다.
- 챗GPT는 여전히 완벽하지 않다. 거짓 정보를 사실처럼 말하는 할루시네이션 문제, 데이터의 저작권 문제, 악의적 활용에 대한 우려, 막대한 에너지 소모로 인한 환경 문제까지 인공지능이 일상에 가져다준 편리함만큼이나 해결해야 할 과제도 많다.
- 새로운 기술은 언제나 문제를 안고 있지만 인류는 항상 이를 보완하며 발전을 거듭해왔듯이 챗GPT도 다르지 않다.
  - 기술이 우리 삶을 변화시키는 것은 분명하지만, 그 변화를 어떤 방향으로 설계하고 통제할 지는 결국 인간의 몫

#### 인간을 능가하는 GPT-4의 등장

- 2022년 겨울에 등장한 챗GPT가 전 세계 월간 사용자 1억 명에 달할 정도로 뜨거운 반응을 얻은 이후 불과 몇 개월 만인 2023년 봄, 새롭게 등장한 GPT-4의 성능은 놀라운 수준이었다.
  - 인공지능 관련 업계에서는 2016년 알파고가 세상을 놀라게 한 이후 두 번째 빅 웨이브가 도래했다고 평가하고 있다.
- GPT-4는 오픈AI가 개발한 `초거대 언어 모델(LLM; Large Language Model)`의 이름이다.
  - 챗GPT는 GPT-4와 같은 모델을 활용하는 챗봇 서비스의 이름. 이전에 챗GPT는 언어 모델 자체를 지칭하기도 했으나, 이후 서비스의 이름으로 자리잡았다.
- 챗GPT 등장 당시, 돌풍의 핵심은 전세계를 대상으로 과감하게 무료 서비스를 진행했다는 점이었다. 오픈AI가 전 세계 공개 서비스를 결정한 것은 '경제적 해자\*'를 구축한 사례라 할 수 있다.
  > \* 해자 : 적의 접근을 막기 위해 성 주위를 둘러싼 방어용 호수
- 오픈AI 출신의 연구원들이 나와서 창업한 앤트로픽, 구글과 페이스북 출신의 연구원들이 창업한 미스트랄AI, 네이버를 비롯한 국내 기업들도 GPT-4의 아성에 도전하고 있다.
- 챗GPT 같은 서비스를 개발하는 데는 수백, 수천억 원에 이르는 막대한 비용이 들기 때문에 대부분의 기업들은 자사의 LLM을 외부에 공개하지 않는 것이 일반적이다.
  - 챗GPT 역시 서비스는 공개되어 있지만 모델 자체는 공개하지 않고 있다.
  - 그러나 메타는 GPT-4에 견줄만한 성능을 지닌 모델 라마를 누구나 사용할 수 있도록 오픈소스로 공개했다.
- 오픈AI는 인공지능 발전의 올바른 방향을 제시하고자 일론 머스크의 주도 하에 비영리 단체를 표방하며 기부로 자금을 조달하여 만든 연구소였다.
  - 오픈AI는 어떤 집단이나 기업에 귀속되지 않는 `범용 인공지능(AGI; Artificial General Intelligence)` 개발을 목표로 했다.
  - AGI는 특정 작업에 특화된 좁은 인공지능이 아닌 인간과 같은 수준의 종합적인 사고 능력을 갖춘 인공지능을 의미한다.
  - 오픈AI는 이미지 생성 모델 달리(DALL-E), 음성인식 모델 Whisper, 프로그래밍 코드 작성 지원 모델 Codex(현재 GitHub Copilot 이라는 이름으로 서비스 중), 동영상을 재생하는 Sora 같은 혁신적인 모델들을 연이어 선보였다. 그 중 가장 유명한 것이 `GPT(Generative Pre-trained Transformer)` 시리즈

#### GPT의 핵심인 언어 모델 살펴보기

> 언어 모델(LM; Language Model)  
> 자연어(사람들이 일상적으로 사용하는 자연스럽고 직관적인 언어)의 확률적 모델. 언어의 구조와 패턴을 학습해 언어를 이해하고 생성할 수 있도록 설계된 모델

- 언어 모델의 근원은 1883년 프랑스의 언어학자 미셸 브레알이 제안한 개념인 의미론(Semantics)애서 살펴볼 수 있다.
  - 의미론은 언어의 구성과 의미, 변화, 단어 간 연결 구조 등을 체계적으로 연구해 현대 의미론의 토대를 마련했다.
- 본격적인 현대 언어 모델의 개념은 1980년대 IBM에서 시작됐다고 볼 수 있다. 당시 IBM은 수많은 문장을 이용해 통계적인 방식으로 언어 모델을 구축했다.
  - 단어의 번역 확률, 문장 중간의 단어 예측 모델, 다음 단어 예측 모델 등 다양한 형태의 확률 모델을 만들었다.
- 언어 모델은 인간의 언어를 컴퓨터로 모델링하는 여러 방식 중 하나로, 여러 분야에서 유용하게 활용된다.
  - 언어 모델은 문맥 속에서 가장 가능성이 높은 단어를 찾는 역할을 한다. 문장의 확률을 기반으로 잘못 인식된 부분을 보정하는 것

#### 초거대 모델, 크기 전쟁을 시작하다

- 최근의 언어 모델들은 수천억 개 이상의 매개변수를 갖고 있으며, 인터넷에 있는 방대한 양의 텍스트 데이터로 학습된다.
  - GPT-4는 약 1조 8,000억 개의 매개변수를 가진 것으로 추정됨
- 이전의 언어 모델은 대부분 특정 작업에 최적화된 학습 데이터가 반드시 필요했다. 이를 `지도 학습(Supervised Learning)`이라 함
  - 예를 들어 긍정/부정을 판단하는 분류 작업 학습 시, 어떤 문장이 긍정/부정인지 사람이 일일이 판별하여 정답을 달아줘야 했다. 이를 `라벨링(Labeling)`이라 함
- 그러나 GPT 등장 이후, 대규모 `비지도 학습(Unsupervised Learning)`이 다양한 자연어 처리 작업에서 높은 성능을 발휘할 수 있다는 점이 입증되었다.
- 실용적이고 과학적인 답변을 하는 모델을 만들려면 학습 문장도 과학적이어야 한다.
  - 쓰레기를 넣으면 쓰레기가 나온다. (Garbage In, Garbage Out)

#### 할루시네이션, 환각 또는 환상

> 할루시네이션(Hallucination)  
> 환각, 환상. 존재하지 않는 무언가를 마치 존재하는 것처럼 얘기하는 현상. LLM이 엉뚱한 정보를 정답처럼 얘기하는 상황

- 연구자들은 할루시네이션 문제를 극복하기 위해 다양한 방법을 시도 중이다.
  - 인간 피드백 강화학습(RLHF; Reinforcement Learning from Human Feedback), 검색 증강 생성(RAG; Retrieval-Augmented Generation) 등

#### 과연 GPT-4의 비밀은?

- 오픈AI는 GPT-4에 대해 아무것도 공개하지 않았다. 조지 호츠에 의해 알려진 몇 가지 신뢰할 만한 정보가 있을 뿐

  - GPT-4는 2,200억 개의 매개변수를 분야별(220B) 8개 모델로 학습하고 게이트를 통해 가중치를 조정하는 전문가 혼합(MoE)\* 구조를 사용했다.

    > \* `전문가 혼합(MoE; Mixture of Expert)`  
    > 여러 개의 모델을 만들어두고 필요한 모델만 선택하여 계산하는 구조. 원래 LLM은 모델 전체가 계산에 모두 투입되는 구조인데, MoE는 필요한 전문가 모델만 선별적으로 계산에 투입하여 불필요한 계산을 줄일 수 있을 뿐 아니라, 더 정확한 답변을 얻을 수 있다.

- 일론 머스크와 소송을 진행하며 공개된 오픈AI의 내부 문건에 따르면, 기술이 어느 정도 성숙도에 이르면 더 이상 기술을 공개하지 않기로 논의했음이 나와있다.
  - 인간을 뛰어넘을 수 있는 인공지능 기술이 무분별하게 공개될 경우 오히려 인류에게 더 위험할 수 있기 때문에 안전하고 책임감 있게 기술을 배포하기 위해서라는 게 비공개 이유
- 이외에도 GPT-4의 기술 비공개는 크게 두 가지 의미를 지닌다.
  1. 이제 언어 모델은 연구 단계를 넘어 제품화 단계에 돌입했다.
  2. 연구 성과로 공개할 내용이 많지 않을 수도 있다.

---

#### Comment

- (p.27-28) AI 연구의 공공성과 윤리성을 표방하지만 AI 개발에는 막대한 예산이 필요하기 때문에 영리 추구가 불가피하다는 모순. 결국 AGI가 온전한 공익성을 갖기는 어려운 걸까?
  - 이와 관련하여 일론 머스크가 소송을 제기하기도 했는데, 그의 의도는 정말 영리성을 배재한 걸까. 의문이 든다.
  - [참고] https://brunch.co.kr/@capitaledge/73
- (p.41) 소설, 영화 대본, 카피라이팅 같은 창의적인 글쓰기가 필요한 경우엔 오히려 할루시네이션을 유도해야 한다는 사실은 새로웠다. AI의 환각 현상은 극복해야 하는 문제라고만 생각했었는데, 오히려 필요할 수도 있겠구나. 그럼 개발하는 사람 입장에서 그 둘 사이의 균형을 어디에 두어야 할까.
- 알쓸별잡에서 챗GPT에 관해 대화하는 편을 재밌게 봤었는데, 1장이 그 편과 겹치는 내용이 많았다. 이번 장을 읽으면서 그 편 클립 영상도 다시 찾아봤다.
  - https://youtu.be/pS8Tt2W4F3A?si=J9Gwf52mLRpqFY6S
