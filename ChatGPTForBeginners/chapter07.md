## 제7장 엔비디아와 반도체 전쟁

#### 청바지를 판매하는 엔비디아의 탄생

- 게임 그래픽 카드는 3차원 그래픽 게임의 가속을 위해 사용하는 장치다.
- 엔비디아는 일찍이 게임 외에도 다양한 분야에 GPU가 쓰이길 바랬다. 초기에는 그래픽스로 응용 분야를 확장했다.
- 엔비디아는 2004년 스탠퍼드에서 GPU를 연구하언 이언 벅(Ian Buck)을 채용하고, 2006년 `CUDA` 라는 플랫폼을 만들었다.
  - 원래 GPU는 셰이더 같은 생소한 그래픽스 전용 언어로 코딩해야 했다. 또한 용도별로 유닛이 구분되어 있어(ex. 버텍스 처리에 8개 유닛, 조각 생성에 24개 유닛, ..) 활용이 어려웠다.
  - CUDA는 각각의 유닛을 통합한 새로운 아키텍처로, C++ 언어로 코딩할 수 있어 연구자들이 쉽게 GPU에 접근할 수 있게 되었다.
  - 이언 벅은 20여 년이 지난 지금도 엔비디아에서 전 세계 데이터센터 비즈니스를 책임지는 부사장으로 근무 중이다.
- CUDA 발표 초기에는 엔비디아가 쓸데없는 기술에 투자한다며 많은 비난을 받았다. 기술개발 투입비가 100억에 달했고, 모든 GPU를 CUDA 호환으로 만들려니 칩 생산 비용도 크게 증가했기 때문. 더욱이 2008년 미국 서브프라임 모기지 사태로 주가가 80% 가까이 빠진 시기였다.
- 2009년 스탠퍼드 대학교에서 인공 신경망에 GPU를 도입한 실험으로 70배나 빠른 학습 결과를 보인 이후, 본격적으로 인공지능 연구에 GPU가 도입되기 시작했다.
- 엔비디아는 하드웨어 회사임에도 일찍이 소프트웨어에 많은 투자를 했다.
  - 지금도 여전히 모든 딥러닝 라이브러리가 CUDA를 우선으로 지원한다.
- 엔비디아는 CUDA 생태계와 최고의 GPU 성능으로 대안 없는 완전한 독과점 시장을 형성하고 있다.

#### 세계 최고의 엔비디아 GPU와 이를 뒷받침하는 SK하이닉스 HBM

- 엔비디아에서 만드는 GPU에는 여러 종류가 있다.

  - 인공지능에 사용되는 GPU는 데이터센터 GPU라고 해서 일반 GPU보다 훨씬 비싸다. 인공지능용 GPU는 오로지 인공지능 용도로만\* 사용할 수 있다.

    > GPGPU(General Purpose Graphics Processing Unit) : 그래픽이 아닌 범용적인 용도의 GPU

  - 가정용 PC에 설치하는 GPU는 RTX라는 이름으로, 게임 그래픽 전용이다.

- 게임용 GPU와 데이터센터 GPU의 가장 큰 차이점은 메모리 크기이다.
- 원래 메모리는 속도보다 용량이 중요했다. 이미 컴퓨터의 모든 장치 중에서 가장 빠르기 때문에 굳이 더 빨라야 할 필요는 없기 때문.
  - 컴퓨터 전체의 동작에서 느린 속도의 원인은 대부분 느린 디스크의 문제였다.
- 그러나 딥러닝에 본격적으로 활용되기 시작하면서 메모리가 훨씬 더 빨라져야 했다. 그래서 등장한 메모리가 `HBM(High Bandwidth Memory)` 이다. 문자 그대로 '고대역폭 메모리'를 뜻한다.
  - 딥러닝은 엄청나게 많은 데이터로 계산하는 작업이다. 예를 들어 GPT-3 175B 모델을 사용한다면 2바이트 매개변수로 로딩을 해도 350GB나 되는 메모리를 차지한다. LLM이 토큰을 하나 생성하기 위해서는 이렇게 큰 데이터를 매번 읽어들여야 한다.
- 엔비디아의 GPU에 HBM이 탑재되므로 HBM을 만드는 회사는 엔비디아가 잘 되면 덩달아 수익을 낸다. 이 제품을 만드는 회사가 바로 SK하이닉스.
  - 하이닉스는 HBM을 세계 최초로 개발하고 엔비디아에 독점 납품하고 있다.
- 기존에는 메모리의 용량이 중요했기 때문에 CPU와는 약간 떨어져 있었다. 충분히 많은 공간을 확보할 수 있는 위치에, 메모리를 나란히 장착했다. 하지만 HBM은 GPU 바로 옆에 위치해 있다. 딱 붙어 있으니 훨씬 더 빠른 초고속 통신이 가능하다.
- 또한 HBM은 속도를 높이기 위해 훨씬 더 많은 연결을 한다. 메모리를 수직으로 쌓아 올리고 구멍을 뚫어 연결해 엄청나게 많은 도로를 수직으로 만들고 이를 GPU에 직접 연결시켰다.
- 엔비디아 H100 GPU의 HBM 대역폭은 3.35TB/s로, 1초에 3TB를 넘게 이동시킬 수 있다.

#### 전 세계는 반도체 전쟁 중

- 반도체는 '산업의 쌀'이라 불린다. 어디에나 반도체가 있지만, 반도체 없이는 디지털 세상도 존재할 수 없다.
- 1990년대 이전까지만 해도 우리나라의 반도체 산업은 존재감이 미미했다. 세계 최초로 반도체를 개발한 미국을 필두로 유럽과 일본 업체가 추격 중인 상황이었다.
  - 필립스, 지멘스 같은 유럽 회사와 도시바, NEC(일본전기), 히타치, 후지쯔, 미쓰비시 같은 일본 회사들이 전 세계 반도체 업체를 점령하고 있었다.
  - 특히 1980년대 일본은 세계 2위 경제 대국으로 기세등등하던 시절이었다. 일본 기업들은 높은 기술력, 저렴한 가격으로 종주국인 미국 기업들이 대부분 시장에서 철수했다.
- 일반적으로 반도체는 시스템 반도체와 메모리 반도체로 구분된다.
  - 시스템 반도체는 CPU를 떠올리면 되고, 메모리 반도체는 말 그대로 메모리를 떠올리면 된다.
- 인텔은 메모리 반도체로 시작했지만 이후에 CPU가 대박을 터뜨리고 전 세계 CPU 시장을 사실상 독점하면서 시스템 반도체 분야의 1인자가 됐다.
- 일본 기업들은 전 세계 메모리 반도체 시장을 점령한다. 이때 인텔도 메모리 시장에서는 과감히 철수하고 말았다.
- 미국 정부가 일본 기업들에 제재를 가하기 시작하면서 혼란의 틈바구니에서 고속 성장을 거듭한 나라가 바로 한국이다.
  - 우리나라는 일본 기업들이 휘청이는 사이 메모리 반도체 기술을 꾸준히 발전시켰고, 2025년 기준 삼성전자가 세계 1위, SK하이닉스가 세계 2위를 차지하고 있다.

#### 엔비디아를 맹렬히 추격하다: AMD, 구글, 인텔, 아마존, 마이크로소프트, 메타

1. AMD, 엔비디아의 가장 위협적인 경쟁자

- 엔비디아가 게임 그래픽 카드를 생산하던 시절에 ATI라는 회사에서 출시하던 라데온(Radeon)이라는 그래픽 카드는 한 때 엔비디아를 능가하는 인기를 누렸다. AMD는 이 회사를 2006년에 인수했다.
- 엔비디아에 CUDA가 있다면 AMD에는 이와 유사한, 2016년에 출시한 ROCm이라는 플랫폼이 있다.
- 엔비디아의 대표 리사 수(Lisa Su)는 대만 태생으로, MIT에서 반도체로 박사 학위를 받은 정통 연구자 출신의 여성 CEO로, 탁월한 리더십을 갖췄다.
  - 그녀가 AMD에 합류할 당시인 2012년, AMD는 언제 망해도 이상하지 않을 정도로 위태로운 상황이었으나, 리사 수가 GPU에 집중, GPU의 가격을 낮춰 가성비를 높였고, 이외에도 여러 현명한 판단을 통해 AMD를 파산에서 구해냈다.

2. 구글, 전용 칩으로 도전하다

- 구글은 자사의 인공지능 가속기를 `TPU(Tensor Processing Unit)` 라는 별도 이름으로 부르며, 2016년에 처음 공개했다.

  > 텐서(Tensor)  
  > 데이터를 다차원 배열에 표현하는 개념으로, 딥러닝에서 값을 표현하는 데 사용. 텐서는 딥러닝에서 다양한 데이터를 처리하는 데 중요한 역할을 한다.

  - 2016년은 알파고 바둑 대국을 벌였던 해로, 알파고가 바로 TPU를 이용해 개발된 프로그램이다.

- 구체적으로 TPU는 행렬 연산을 최적화하여 고속으로 수행하는 장치다.
- 특히 수축기 배열(Systolic Array) 구조를 도입하여 기존의 GPU보다 대규모 행렬 연산을 훨씬 더 효율적으로 수행할 뿐 아니라 전력 소비도 낮췄다.
- 일반적으로 칩 개발은 매우 복잡하고 어려운 기술로, 개발 기간만 수년 이상 소요된다. 그러나 구글은 칩을 처음 만들면서도 단 15개월만에 생산부터 서버 배포까지 완료했다.
  - 이는 구글의 탁월한 프로젝트 관리 역량을 단적으로 보여준다.

3. 인텔, 반도체 제왕의 새로운 도전

- 한때 인텔은 반도체 그 자체를 의미했다. 애초에 창업자가 집적 회로를 세계 최초로 만든 사람이기도 하다.
- 인텔은 1971년에 상업적 용도의 CPU를 세계 최초로 만들어냈고, 전성기 때는 CPU 시장의 80% 이상을 점유했다.
- 그러나 인텔은 PC 시대를 지나 모바일 시대가 열릴 때 이에 적응하지 못 했고, 인공지능 경쟁에서도 뒤처졌다.
- 인텔은 가우디(Gaudi)라는 인공지능 가속기를 만든 이스라엘의 반도체 기업 하바나랩스를 2019년에 2조원이 넘는 금액에 인수하여 제품을 발전시켜왔다.
- 인텔은 CUDA에 대항하기 위한 통합 가속 단체(Unified Accelerarion (UXL) Foundation)를 조직해 오픈 생태계를 꾸리려는 노력도 하고 있다.
  - 이 단체에는 구글, 퀄컴, 삼성 등이 참여했는데, 이들은 CUDA와 유사한 소프트웨어를 오픈소스로 만들었다.
  - 이들은 `oneAPI` 라는 통합 인터페이스를 만들어 활용 가능한 수준으로 완성한 상태다. oneAPI는 하나의 단일 API로 모든 장비에 사용할 수 있게끔 하는 기술이다. 엔비디아의 CUDA가 엔비디아의 GPU에서만 동작하는 것과 대조적.
- 최근 인텔은 네이버와 공동 연구소를 설립하여 반도체 시장에서 새로운 경쟁력 확보를 위해 전략적 동맹을 맺었다.
- 그러나 인텔은 2024년 3분기에만 23조 원에 달하는 적자를 기록해 인텔을 대표하는 입지전적한 인물인 CEO 팻 겔싱어 조차도 사임하게 되었다.

4. 자체적인 인공지능 가속기를 만드는 회사들

- 엔비디아 GPU에 대한 의존도를 줄이기 위해 대부분 빅테크 기업들은 자체적인 인공지능 가속기를 제작하고 있다.
- 전 세계 3대 클라우드 서비스인 AWS, GCP, Azure 모두 자체 칩을 사용한 딥러닝 서비스를 제공하고 있다.
- 메타의 인공지능 가속기는 자사의 추천 모델에 특화된 칩이다.
- 이들이 만드는 인공지능 가속기는 더이상 GPU가 아니다. GPU란 애초에 그래픽 처리 장치를 의미하므로. 엔비디아와 AMD, 인텔 정도를 제외하면 그래픽을 처리하는 장치는 만들지 않기 때문에 이외의 회사들이 만드는 인공지능 가속기는 `NPU(Neural Processing Unit)` 라고 부른다.
  - 구글의 TPU, 엔비디아의 GPGPU도 모두 NPU의 일종

#### 엔비디아와 다르게 경쟁하다: 애플, 그록, 텐스토렌트, 퓨리오사AI, 하이퍼엑셀

1. 온디바이스 AI, 내 손 안에서 바로 동작하다

- 애플은 이미 자체적으로 NPU 아키텍처를 개발하여 아이폰 같은 기기에 탑재하고 있다. 아이폰에 탑재되는 모바일 칩은 크기가 작기 때문에 CPU와 NPU를 하나의 단일 칩으로 만드는데, 이런 걸 `모바일 AP(Application Processor)`라 하며, 여러 기능을 하나의 칩에 통합했다 하여 `SoC(System on Chip)` 이라 한다.
  - 당연히 삼성전자도 마찬가지
- 모바일 등에서 NPU를 이용해 직접 인공지능 서비스를 제공하는 것을 `Edge AI` 또는 `On-Device AI` 라고 하는데, 앞으로 매우 주목받을 분야일 것
- 챗GPT를 포함한 모든 클라우드 형태의 서비스에는 보안 문제가 존재하지만, 온디바이스 AI는 데이터를 외부 서버로 보내지 않고 기기 내에서 바로 처리하기 때문에 정보 유출의 위험이 적고 훨씬 더 높은 수준의 보안을 제공한다.
- 또한 온디바이스 AI는 데이터가 클라우드 서버로 전송되어 처리되는 기존 방식과 달리 기기 자체에서 인공지능 연산을 수행하므로 데이터 전송에 따른 네트워크 지연이 없고 빠른 응답이 가능하다.
  - 클라우드 기반 LLM 서비스들도 꽤 빠르지만, 인터넷이 안 되는 지역이 많은 나라에서는 큰 장점으로 작용할 것이다.

2. 그록, 현존하는 가장 빠른 인공지능 가속기

- TPU 설계에 참여한 바 있는 구글 출신의 반도체 전문가가 창업한 회사인 그록(Groq)은 자사의 인공지능 가속기를 LPU(Language Processing Unit)라 부르며, LLM에 특화된 칩임을 강조한다.
- SRAM은 GPU 코어 안 쪽에 탑재된 메모리로, 아예 GPU에 내장되어 있어서 엄청나게 (HBM보다도) 빠르다. 대신 구조가 복잡하고, 저용량 고비용이다.
- 그록은 SRAM만으로 LLM이 돌아갈 수 있도록 여러 장의 칩을 하나로 연결했다. SRAM의 최대 용량이라고 해봐야 230MB 정도에 불과한데, 70B 모델을 돌리기 위해 약 600여 장의 칩을 하나로 연결해버린 것.
  - 무식한 방법이지만 SRAM이 워낙 빠르다 보니 대단한 속도를 보였다. 그록에 탑재된 SRAM의 속도는 무려 80TB/s에 달한다. HBM보다 24배 정도 더 빠른 셈
- 그록의 차세대 칩은 더 빨라지고 전력 효율도 20배까지 개선 예정이며, 이를 위해 삼성전자와 계약하여 최신 4나노 공정에서 생산 예정이다.

3. 세레브라스, 세계 최대 크기의 칩을 만들다

- 세레브라스(Cerebras)는 웨이퍼 스케일 엔진(Wafer Scale Engine)이라는 세계 최대 크기의 칩을 만든다.
- 엔비디아의 H100이 800억 개의 반도체 소자를 집적한 데 반해, 세레브라스의 최신 모델인 CS-3은 단일 칩에 4조 개의 반도체 소자를 집적하고 있다. 단일 칩으로는 세계 최대 속도를 자랑한다.
- 그록과 마찬가지로 SRAM을 사용해 속도를 올렸는데, 원래 SRAM은 조금밖에 장착할 수 없지만 칩의 크기가 크다보니 44GB나 탑재하고 있다.
- 가격이 비싸고, 전력 문제, 아직 검증이 부족한 문제 등이 있으나 2017년에 오픈AI가 자체 반도체 확보를 위해 세레브라스의 인수를 검토했을 정도로 반도체 분야에서는 유망하다.

4. 텐스토렌트, 반도체 업계 슈퍼스타의 도전

- 텐스토렌트의 대표 짐 켈러(Jim Keller)는 반도체 업계에서 전설적인 인물로, 그는 AMD, 애플, 테슬라 등 주요 기업에서 핵심적인 역할을 담당하며 동시대 최고의 칩을 만들어냈다.
- 다른 기업과 반대로 저렴하면서도 쓸 만한 대중적인 인공지능 가속기를 만드는 것이 켈러의 방식이다.
- 메모리도 일반 PC에서 사용하는 것과 동일한 것을 사용하며, 그만큼 가격도 저렴하다.
- 게다가 핵심 소프트웨어를 모두 오픈소스로 진행하고 있다. 일종의 GPU 해커들을 위한 놀이터를 만들고 참여를 유도하는 것

5. 퓨리오사AI, 메타가 관심 갖는 국내 기업

- 퓨리오사AI는 2017년에 설립된 우리나라의 팹리스(Fabless) 스타트업으로, AMD와 삼성전자에서 반도체를 연구하던 백준호 대표가 이끌고 있다.
- LLM에 최적화한 레니게이드(RNGD)는 48GB의 HBM을 장착했다. 동일한 전기를 소모할 때 엔비디아 제품보다 좀 더 효율적으로 동작한다.
- 레니게이드는 TCP(Tensor Contracction Processor)라는 아키텍처를 채택해 효율성을 높였다. 고정된 크기의 데이터만 처리하는 수축기 배열 구조와 달리 TCP는 동적으로 재배치할 수 있는 더 작은 컴퓨팅 유닛을 갖고 있어 더욱 유연하게 동작한다.
- 퓨리오사AI는 소프트웨어적 문제를 파이토치 지원으로 해결하려 하고 있다.

6. 하이퍼엑셀, LLM에 특화된 칩을 개발하다

- 카이스트 김주영 교수가 창업하고, 삼성전자에서 반도체를 연구하던 이진원 CTO가 합류한 AI 반도체 스타트업 하이퍼엑셀은 LLM에 특화된 반도체 칩을 개발하고 있다.
- 하이퍼엑셀의 핵심 기술은 AI 연산에서 가장 중요한 두 가지 요소인 연산과 메모리 성능 균형에 초첨을 맞추는 것이다.

#### TSMC, 모두가 청바지 원단 회사를 꿈꾸며

- 앞서 소개한 기업들은 모두 반도체를 설계만 하고 생산하지 않는다. `TSMC(Taiwan Semiconductor Manufacturing Company)`는 반도체 분야 생산 기업이다.
- TSMC는 미국에서 반도체 엔지니어로 일하던 모리스 창이 고국인 대만으로 돌아와 설립했다.
- 모리스 창은 향후 반도체 시장이 설계를 전문으로 하는 `팹리스(Fabless)` 기업과, 제조를 위탁받아 생산을 전문으로 하는 `파운드리(Foundry)` 기업으로 나뉠 것으로 전망하고 이 생각을 바탕으로 TSMC를 설립했다.
  - 결과적으로 모리스 창의 예측은 정확했고, 전 세계 반도체 산업의 판도를 크게 바꿨다. 엔비디아도 팹리스 회사.
- TSMC는 파운드리 사업으로 세계 최고의 반도체 기업으로 성장했다. 2024년도 한 해 매출이 약 130조 원이며 반도체 부문에서 압도적인 세계 1위다.
- 모바일 칩을 만드는 대부분의 회사는 영국의 ARM으로부터 라이선스를 취득해 설계에 필요한 아키텍처를 사용한다.
  - ARM은 원하는 기업에 라이선스를 판매하는 방식으로 운영된다.
- 반도체 설계 소프트웨어를 만드는 회사는 케이던스, 시놉시스, 지멘스EDA 등이 있는데 모두 미국 회사다.
- 반도체 최신 공정이 가능한, 전 세계에서 딱 두 군데 뿐인 회사로 TSMC, 삼성전자가 있다. TSMC는 최신 공정에서는 삼성보다 훨씬 앞서 있다고 평가 받는다.
- TSMC가 최신 공정으로 생산하기 위해서는 네널란드 ASML에서 만드는 극자외선 리소그래피 장비가 필요하다. ASML은 이 장비를 생산하는 전 세계에서 유일한 회사다.
  - 첨단 기술이 집약된 ASML의 장비는 그 복잡성과 희소성으로 대당 수천억 원에 달하는 가격을 형성하고 있다.
- 독일의 트럼프(TRUMF)라는 회사는 주석 방울을 맞힐 수 있는 세계 최고의 정밀 레이저를 만들고, 독일의 또 다른 기업 자이스(ZEISS)는 이렇게 만든 극자외선 광선을 모아서 실리콘 칩에 쏴줄 수 있는 매끄러운 표면의 거울을 만들고, 미국의 사이머(Cymer)는 트럼프, 자이스와 합작해 여기에 필요한 광원 장비를 만든다.
- ASML은 5,100개 이상의 공급업체를 갖고 있으며 40%는 네덜란드에서, 40%는 유럽의 다른 지역(주로 독일)에서, 13%는 미국에서, 7%는 일본을 비롯한 아시아에서 공급받는다.
- 반도체를 원료인 실리콘을 만들기 위해서는 '실리카 샌드'라 불리는 고순도 석영 모래가 필요하다.
  - 이 모래는 미국에 있는 작은 마을, 스프루스 파인(Spruce Pine)이라는 전 세계 딱 한 군데에서만 생산된다.
- 스프루스 파인에서 모래를 채취하기 위해 광산을 운영하는 기업으로는 벨기에의 시벨코(Sibelco), 노르웨이의 더쿼츠코프(The Quartz Corp) 등이 있다.
- 실리콘을 웨이퍼로 가공하는 일본의 상위 2개 업체가 전 세계 시장의 절반 이상을 차치(과점)한다.
- 반도체 생산 과정 : 스프루스 파인에서 모래 채굴 → 노르웨이 북부 드래그로 7,000km 운반되어 정제, 고순도 실리콘 원료로 처리 → 일본의 전문 소재 업체로 운반되어 실리콘을 웨이퍼로 가공, 99.999999999%의 고순도 실리콘을 잉곳(Ingot)으로 만듦 → 잉곳 덩어리를 얇게 절단하고 표면을 매끄럽게 다듬으면 실리콘 웨이퍼로 탄생 → TSMC나, 삼성전자 등에서 반도체를 생산하는 데 사용

#### 중국의 도전 vs 미국의 견제

- 반도체 설계와 생산은 촘촘한 글로벌 공급 사슬망에 속해있다. 분야별로 글로벌 단위의 분업화와 동시에 소수 기업에 극단적으로 쏠려 있다.
- 어플라이드머티리얼스(Applied Materials)는 실리콘 웨이퍼에 얇은 필름을 입히는 증착 장비를 만드는 세계 최대 반도체 장비 회사, 램리서치(Lam Research)는 실리콘 웨이퍼에서 특정 부분을 제거해 미세 패턴을 형성하는 식각 장비 분야에서 세계 최고 기술력을 가진 회사, KLA는 실리콘 웨이퍼에 생기는 나노미터 단위 결함을 감지하는 측정 장비 분야의 세계 최고 회사이며 모두 미국 회사다.
- 중국은 모든 반도체 기술의 자급자족을 목표로 하고, 반도체 설계에만 집중하던 미국은 제조를 다시 미국 내에 들이고자 파격적인 지원을 하고 있다.
- 챗GPT 이후로 LLM 열풍이 불고, LLM의 크기가 커질수록 더 좋은 성능을 내는 규모의 법칙으로 인해 많은 기업이 모델의 크기에 더욱 집중하고 있다.
  - 모델의 크기를 키우기 위해선 대규모의 GPU가 필요하고, 대규모 GPU 생산을 위해서는 반도체 인프라가 중요하다.
  - 즉, 인공지능이 발전할수록 더욱 많은 반도체를 필요로 한다.

---

#### Comment

- (p.295-305) 반도체 분야에 대해서는 잘 알지 못했는데, 새롭게 알게 된 것들이 많아 유익했다.
- 7장은 전반적인 인공지능 산업 생태계를 이해하기 좋은 내용이었다. 최근 인공지능으로 핫해진 기업들이 구체적으로 어떤 포지션에 있는 지를 알지는 못 했는데 조금 더 깊게 알 수 있었다.
- (p.332) 모래에서 추출한 실리콘으로 반도체의 집적 회로를 만든다. 이 실리콘은 실리콘밸리의 그 실리콘이다. 재밌는 사실.
- (p.336-340) 집적회로, 극자외선 리소그래피, 3나노미터 노광장비, 주석 방울, .. 어럽다.
- (p.341-344) 반도체 생산 과정에 독점적인 기업이 꽤나 많다. 소수 기업에 극단적으로 쏠려 있는 공급망.
