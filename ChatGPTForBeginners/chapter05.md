## 제5장 프롬프트 엔지니어링의 마법

```
< Discussion >

(같은 질문을 가져올 가능성이 높긴 한데..,)
이 챕터의 마지막에 나온 질문을 주제로 하고 싶습니다.

프롬프트 엔지니어의 미래는 어떻게 될까요? 새로운 전문 직종으로 자리 잡을까요, 아니면 인터넷정보검색사처럼 시대의 흐름 속에 사라질까요?

전문 직종으로 자리잡기 위해서는 프롬프트 엔지니어의 전문성(차별성)을 어디서 찾을 수 있을까요?
```

#### 프롬프트 엔지니어링으로 원하는 결과 얻기

- 모델 구조를 연구하고 학습하는 일은 소수 연구자들의 몫이지만 어떻게 질문하느냐는 사용자의 몫

> `프롬프트 엔지니어링(Prompt Engineering)`  
> 인공지능(AI), 특히 대규모 언어 모델(LLM)이 사용자가 원하는 최적의 결과물을 생성하도록 입력 프롬프트를 설계하고 최적화하는 기술 및 방법론

- 초기에는 경험에 의존해 단순 시도와 오류를 반복하며 프롬프트를 입력하는 것을 '블라인드 프롬프팅(Blind Prompting)', 지시사항 작성에 집중하는 것을 '프롬프트 라이팅(Prompt Writing)' 등으로 구분해 지칭했으나, 오늘날 다양한 프롬프팅 기술과 전략을 포괄하는 개념으로 '프롬프트 엔지니어링' 이라는 용어가 자리를 잡았다.
- `맥락(Context)` 은 LLM이 잘 답변할 수 있도록 추가 정보를 제공하는 것을 말한다. 맥락을 추가해주면 훨씬 더 적합한 답변을 기대할 수 있다.
- 오픈AI의 경쟁사 앤트로픽은 프롬프트 엔지니어를 채용하면서 37만 달러의 연봉을, 국내 인공지능 스타트업 뤼튼은 프롬프트 엔지니어를 공개 채용하며 기본 연봉 1억원을 제시한 바 있다.
  - 그러나 1990년대 후반, 인터넷이 급성장하면서 유망한 직종으로 각광받던 '인터넷 정보검색사'처럼 반짝하다 사라질 직업일지도 모른다는 우려도 있다.
  - 이제는 누구나 검색이 일상화된 시대에 살며, 검색은 모두가 사용하는 보편적인 기술이 되었으므로.

#### 예시를 보여주면 더 좋은 결과를 보여드립니다

> `제로샷(Zero-Shot)` : 어떠한 예시도 없이 즉시 추론을 수행하는 경우  
> `원샷(One-Shot)` : 예시를 한 개 제공  
> `퓨샷(Few-Shot)` : 예시를 두 개 이상 제공

- 예시를 제공하면 LLM이 훨씬 더 일관되고 정확하게 대답한다.
- 퓨샷으로 평가하면 대개는 제로샷으로 평가할 때보다 성능이 훨씬 더 좋아진다.

#### 생각의 사슬, 복잡한 문제를 단계적으로 풀기

> `생각의 사슬(Chain of Thought, CoT)`  
> LLM의 추론 능력을 향상시키는 대표적인 기법 중 하나. 단계적 추론을 유도해 복잡한 문제의 정확도를 높이는 방법으로, LLM이 최종 답변에 도달하기까지 중간 추론 단계를 명시적으로 보여줌으로써 추론 과정을 더 투명하고 이해하기 쉽게 만든다.

- 17세기 정치철학자 토머스 홉스(Thomas Hobbes, 1588-1679)는 생각의 흐름(Train of Thought) 이라는 용어를 처음 사용했는데, 이는 인간의 사고 과정을 자연스러운 흐름에 비유한 것이었다.
- 사고 과정에서 연속성은 매우 중요하다. 사고의 흐름이 방해를 받으면 전체 사고 과정이 중단될 수도 있다.
  - 인간의 사고 과정에서 생각의 흐름이 중요하듯이, LLM도 답변을 잘하기 위해서는 생각의 사슬이 중요하다.
- 생각의 사슬은 복잡한 문제를 해결할 때 추론 과정을 개선하는 데 사용한다. 단순히 최종 답변만 제시하는 게 아니라, 중간 단계의 추론 과정을 명확하게 제시해서 답변의 정확도를 높이는 데 도움을 주는 것
  - 특히 복잡한 논리나 추론 작업에서 LLM의 성능을 크게 향상시킨다.
- LLM은 본질적으로 대규모 텍스트 데이터를 기반으로 학습된 패턴을 인식하는 확률 모델일 뿐이므로, 수학적 연산에는 취약한데, 생각의 사슬은 이럴 때 도움을 주는 기법이다.
  - 수학 외에도 비슷한 방식으로 동작하는 상식 추론, 기호적 추론 등
- 생각의 사슬은 굳이 언급하지 않으면 항상 퓨샷 CoT가 된다. 그러나 `제로샷 CoT` 도 있는데, 질문 마지막에 단순히 '자, 단계별로 천천히 생각해봅시다.' 같은 구문을 추가하는 걸 말한다.
  - 예시를 전혀 제시하지 않고 단순히 지시만 했으므로 '제로샷'이다.
- 생각의 사슬이 잘 동작하는 이유에는 여러 요인이 복합적으로 작용하지만 크게 두 가지 요인을 꼽을 수 있다.
  1. 사람의 문제 해결 방식과 유사한 단계별 사고 과정을 모방하기 때문 : 생각의 사슬은 LLM이 복잡한 문제를 더 작고 관리하기 쉬운 부분으로 나눠서 처리하게 한다.
  2. 중간 추론 단계를 명시적으로 표현하기 때문 : LLM은 각 단계에서 정확한 판단을 내릴 수 있고, 오류가 발생하더라도 그 지점을 파악하고 수정하기가 훨씬 더 쉬워진다.
- 매개변수가 1,000억 개 이상 되는 모델은 창발성(느닷없이 나타나는 능력)이 생긴다는 연구 결과도 있다. LLM이 추론하는 것 같은 새로운 능력을 갖게 된다는 것
  - 요즘은 LLM의 성능이 점점 더 좋아지고 있어 창발성을 보이는 매개변수 임계값도 낮아지는 추세

#### RAG, 검색으로 성능을 높이는 마법

> `RAG((Retrieval-Augmented Generation, 검색 증강 생성)`  
> 모델이 답을 만들기 전에, 외부 지식에서 관련 정보를 먼저 찾아와서 그걸 근거로 답변을 생성하는 방식. 즉 LLM이 답을 기억에서 꺼내는 것이 아니라 찾아보고 나서 말하게 만드는 구조

- RAG는 할루시네이션을 막기 위해 프롬프트 상단에 신뢰할 수 있는 외부 소스를 참조해 정보를 제공한다.
- RAG는 LLM의 고질적인 문제인 할루시네이션을 방지한다는 점에서 크게 주목받고 있다. 답변 자체가 실제로 추출한 관련 데이터에 기반하므로 정확성이 높다.
  - 데이터만 있으면 되므로 언제든지 최신 정보를 제시할 수 있으며,
  - 이를 통해 LLM이 잘못된 정보나 오래된 정보를 생성할 가능성도 줄일 수 있다.
- 외부 검색은 대개 벡터 데이터베이스(Vector Database) 같은 별도 솔루션을 사용한다.
- 퍼플렉시티는 RAG를 상업적으로 구현하여 검색을 통해 관련 정보를 채우고, LLM을 통해 답변하는 유료 서비스다.
- 챗GPT도 챗GPT 검색이라는 이름으로 2024년 10월부터 RAG를 제공하기 시작했다. 하단 검색 버튼을 누르고 질문하면 관련 정보를 직접 검색하고 그 정보를 이용해 응답한다.

> `랭체인(Lang Chain)`  
> RAG를 직접 구축할 수 있도록 지원하는 무료 프레임워크 중 가장 유명한 제품으로, LLM을 활용해 RAG를 손쉽게 개발할 수 있도록 외부 데이터 소스, API, 다양한 외부 환경과 연결하는 작업 등을 하나의 블록처럼 두고 마치 레고처럼 조립해서 서비스를 구성할 수 있게 해주는 프레임워크

- 랭체인은 LLM을 자유롭게 바꿔 사용할 수 있으며, 복잡한 작업을 중간에서 단순화해주고, LLM 외에도 다양한 외부 데이터 소스와 연결해준다. 메모리 관리 기능도 있어 중간 정보는 별도 기억할 수 있고, 프롬프트 템플릿을 따로 관리할 수도 있다.

#### 벡터 데이터베이스, LLM의 성능을 높이는 또 다른 기술

> `벡터 데이터베이스(Vector Database)`  
> 단어나 문자의 특징을 숫자 벡터 형태의 데이터로 변환(임베딩)하여 저장하고 검색할 수 있는 데이터베이스 시스템

- 임베딩 벡터, 즉 숫자 값으로 바꿔서 저장하는 이유는 검색을 용이하게 하기 위함이다.
- RAG 구현 시 단순히 구글 검색을 사용해도 되지만, 기업의 기밀 데이터와 같은 비밀 정보인 경우 벡터 데이터베이스를 사용해야 한다.
- 검색 엔진은 특성상 반드시 검색 키워드가 포함되어 있는 문서를 찾는 구조이나, 벡터 데이터베이스는 내용을 수치화하고 이 숫자 값을 이용해 비슷한 숫자를 찾는 형태이므로 꼭 해당 키워드가 포함되어 있지 않아도 된다.
  - 심지어 완전히 다른 내용도 찾을 수 있다. 이를 의미론적 검색(Semantic Search)이라고 한다. 키워드가 일치하지 않아도 의미가 비슷하기만 하면 문서를 찾아낼 수 있다.
- 벡터 데이터베이스는 최근 가장 주목받고 있는 기술로 해외에는 파인콘(Pinecone), 밀버스(Milvus) 같은 제품이 큰 인기를 끌고 있으며, 이외에도 오래전부터 검색엔진으로 유명한 일래스틱서치(Elasticsearch) 같은 제품이 있다. 국내 제품 중에서는 씨홀스(Seahorse) 등이 있다.

#### 고급 프롬프트 엔지니어링 기법을 소개하며

> `생각의 나무(Tree of Thought, ToT)`  
> 생각의 사슬에서 확장된 개념으로, 생각이 하나로 이어지는 게 아니라 여러 개의 경로를 마치 나무의 가지처럼 확장하며 해결하는 방식. 즉 한 가지 방법만 따르지 않고 여러 가능성을 고려한 후 가장 적절한 답을 찾도록 유도하는 방식이다.  
> 정확도를 많이 높일 수 있으나, 그만큼 다양한 후보를 탐색해봐야 하므로 시간이 오래 걸린다.
>
> `토른 프롬프팅(Debate Prompting)`  
> 여러 LLM을 서로 다른 관점에서 논쟁하게 만든 후 이를 종합해 최적의 답을 도출하는 방식. 한 LLM은 찬성 입장을, 다른 LLM은 반대 입장을 취한 후 마지막으로 이를 종합하여 결론을 내리는 방식이다.  
> 서로 반대 입장을 충분히 고려한다는 점에서 비교적 공평한 답, 최적의 답을 찾는데 도움이 되지만, 답을 이끌어내기까지 토론하는 과정에서 많은 시간이 소요된다.

- 이 외에도 역할극을 하는 것처럼 페르소나를 주입하고 관련성 높은 답변을 유도해내거나, 프롬프트에 형식을 지정하고 형식을 따르는 논리적인 답변을 유도하는 기법, 또는 컴퓨터 프로그램처럼 실행 형식을 정의하고 실행 결과를 유도해내는 기법 등 다양한 고급 프롬프트 엔지니어링 기법이 존재한다.

#### 오픈AI o1, 생각을 거듭할수록 더 좋은 결과를 제시하다

- 2024년 9월, 오픈AI는 GPT-4o의 후속 모델로 o1 이라는 역대 최고 성능의 새로운 모델을 공개했다.
- o1은 마치 프롬프트 엔지니어링을 잘한 것처럼 동작하는 모델이다. o1의 모델 자체는 기존 GPT 모델과 크게 다르지 않다. 대신 문장 생성 단계에서, 즉 추론 단계에서 여러 독특한 기법을 활용해 성능을 높였다.
- o1은 좋은 답변을 이끌어내기 위한 프롬프트 과정을 자동화한 것과 비슷하다. 생각하는(Thinking) 과정을 도입해 프롬프트를 단계적으로 고도화하고 최종적으로 가장 좋은 답변을 도출해낸다.
- LLM이 지속적으로 고도화되고 발전하면서 이제 모델만으로는 더 이상 성능을 높이기 쉽지 않다는 의견이 많다. 대신 o1처럼 추론 단계에서 다양한 기법을 활용해 성능을 높이는 방법이 많이 연구되고 있다.
- o1은 기존의 다른 모델과 달리 추론에 많은 시간을 할애한다. 스케일링 법칙에 따르면 모델의 성능은 크기, 데이터 양, 학습 비용(계산량)이 증가하면 이에 비래해 개선된다고 했는데, 이 중 계산량의 증가가 바로 o1이 추구하는 방향이다.
  > `테스트 타임 스케일링(Test-Time Scaling)` : 추론 과정에 시간을 많이 할애할수록 성능은 더욱 좋아진다.

#### 딥시크 R1, 엔비디아 주가를 18% 폭락시킨 중국의 힘

- o1이 등장한 지 몇 달이 지나지 않아 중국에서 o1의 성능을 동일하게 재현한 모델을 오픈소스로 공개했다. 이 회사의 이름은 '딥시크'
  - 엄청난 자금력을 보유한 헤지펀드사를 모회사로 두고 있다.
- 딥시크 R1은 o1과 동일하게 생각하는 과정을 도입해 성능을 높였다. 평가 결과는 o1보다 훨씬 더 좋은 점수를 기록했다.
- 중국은 미국의 강력한 제재를 받고 있다. 엔비디아의 최상급 GPU인 H1000은 미국의 대표적인 대중국 수출 금지 품목이다. 그럼에도 딥시크는 수출이 허용된 훨씬 더 낮은 사양의 GPU를 이용해 o1보다 더 좋은 결과를 만들어냈다.
- 딥시크 R1은 논문으로 자세히 공개되어 있다. 오픈AI가 숨겨두고자 했던 o1의 비밀을 파헤쳐버린 논문인 셈
  - 딥시크 R1은 MoE 구조를 채택했다. 여러 개의 모델을 만들어두고 필요한 모델만 선택하는 방식
  - 여기에 딥시크 R1은 강화학습 알고리즘을 통해 학습됐다. R1은 외부 평가자 없이 동일한 문제에 대해 학생들끼리 여러 후보 답안을 생성한 후 이들을 서로 비교하면서 상대적인 순위를 매기고 순위가 높은 답안에 더 많은 보상을 부여하는 방식으로 학습이 이루어진다.
  - 딥시크 R1은 o1과 마찬가지로 단순히 최종 결과만 내놓지 않고, 모델이 답변을 내기까지의 추론이나 사고 과정을 &lt;think&gt; 태그를 통해 명시적으로 기록하여 내부 로직을 개선하고 더 정교한 답변을 만들어내도록 했다.
  - 한마디로 딥시크 R1은 GPT-4와 o1의 구조를 그대로 따랐다고 할 수 있다.
- 논문에 따르면 딥시크 R1은 오히려 퓨샷으로 예시를 주면 성능이 더 떨어진다. 프롬프트 엔지니어링으로 기교를 부리기보다 LLM을 믿고 예시 없이 바로 질문을 던져야 훨씬 더 좋은 결과를 얻을 수 있다고 한다.
- 딥시크는 모델을 오픈소스로 공개했다.

---

#### Comment

- LLM을 잘 사용하기 위해 가장 필요하고도 유용한 내용이 담겨 있는 챕터였다.
- (p.190-192) 독자 입장에서 굳이 확인하지 않아도 될 텍스트로 3장을 차지. 저자가 분량을 늘리고 싶었나;
- (p.209) 챗GPT 검색 기능은 잘 몰랐는데, 한 번 써봐야겠다.
