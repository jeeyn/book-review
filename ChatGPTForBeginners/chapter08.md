## 제8장 인공지능의 미래와 인류의 도전

#### 무엇이 문제인가

- 인공지능이 엄청난 에너지를 소비하는 것은 부인할 수 없는 사실이다.
- 할루시네이션은 LLM에서 가장 주의해야 할 문제다.
- 더 큰 문제는 의도적으로 진짜 같은 가짜를 만드는 것이다.
  - ex. 가짜 뉴스, 딥페이크(Deepfake)를 통해 연예인의 얼굴을 붙인 포르노 생성 등
- 학습 데이터 생성을 위한 크롤링 과정에서의 저작권 문제도 있다.
- 검색 엔진이 원박스를 도입하면 콘텐츠 제공자의 트래픽이 줄고, 덩달아 광고비도 줄어듦에 따라 수익을 낼 수 없게 된다.

  - 특히 LLM은 모든 것이 원박스나 다름없다.

  > `원박스(OneBox)`  
  > 쿼리에 대한 결과를 직접 검색 결과 상단에 노출하는 방식

- 세상 모든 일에는 편견이 존재하며, 편견을 완전히 없애기는 어렵다. 이러한 사회적 편견은 데이터에도 고스란히 반영된다. 그리고 이 데이터로 학습한 모델은 필연적으로 편향된 결과를 보여줄 수 밖에 없다.
- 개인정보 문제도 있다. 모델을 학습하기 위한 많은 양의 데이터 중 개인정보를 일일이 비식별화 조치하기 어렵다.
- 이유를 설명할 수 없는 것도 문제다. 인간의 두뇌는 아무리 관찰하고 해부해도 사고 과정이 어떻게 이루어지는지를 명확히 설명하기 어렵다. 인간의 두뇌를 본뜬 LLM도 마찬가지. 매개변수를 아무리 살펴본다 한들 알아낼 수 있는 건 없다.
  - 반드시 이유를 설명해야 하는 분야에서는 이러한 한계가 치명적이다. (ex. 자율주행, 의료, 군사)

#### 문제를 극복하기 위한 다양한 노력

- 할루시네이션은 문제라기 보단 현상으로 봐야 한다. 소설, 대본, 마케팅 문구 작성 등 창의적인 글쓰기가 필요한 경우 할루시네이션은 오히려 필수적인 능력이기 때문.
  - 따라서 할루시네이션을 하나의 특징으로 바라보고 이를 보완하기 위한 다양한 방법이 연구되고 있다. (ex. RLHF, RAG 등)
- 기반적인 기술은 대중화될 때 오히려 더 안전해진다. 대중이 조작 가능성을 널리 알면 오히려 기만적인 기술은 힘을 잃는다.
- 가장 좋은 방법은 판별력을 기르는 것이다. 이를 `디지털 리터러시(Digital Literacy)` 라고 한다.

  > `디지털 리터러시(Digital Literacy)`  
  > 디지털 기술과 도구를 효과적이고 비판적으로 이해하고 활용할 수 있는 능력. 여기에는 신뢰할 수 있는 정보와 허위 정보를 구분하는 능력을 갖추는 일도 포함된다.

  - 리터러시를 높이기 위해서는 기술이 더 대중화되어야 한다.

- 원박스 문제 해결을 위해 콘텐츠 제작자들은 데이터 판매와 라이선싱 작업을 하고 있다.
  - LLM을 개발하는 기업들에 자사의 고품질 데이터를 판매하거나 라이선스를 부여하는 것.
- 이미지의 경우 옵트아웃(Opt-Out) 시스템을 도입하는 사례도 있다.
  - 아티스트가 직접 자신의 작품에 옵트아웃 설정을 해두면 이미지 생성 모델을 만드는 회사는 그 작품을 학습에 사용하지 않는다.
  - 2023년 3월에 이미 4만 개 이상의 작품들이 옵트아웃 설정을 신청했다.
- 이외에도 인공지능 회사들이 직접 정당한 콘텐츠 사용 계약을 맺거나 콘텐츠 제공자들에게 인공지능 기술을 제공하면서 상생을 도모하고 있다.
  - 오픈AI는 2023년 AP통신과 계약을 맺었다. 1985년 이후 AP가 작성한 모든 뉴스 데이터를 챗GPT 학습에 사용할 수 있게 허용하고, 오픈AI는 AP통신에 인공지능 기술을 제공하고 활용할 수 있도록 도움을 주는 조건의 계약이었다.
- 데이터 편향 문제를 해결하기 위해서는 기업들의 공정한 데이터 확보 노력이 필수적이다. 다양성 있는 데이터 수집, 지속적인 평가, 올바른 데이터 구축을 위한 체계적인 관리 감독이 매우 중요하다.
- LLM의 동작 원리를 알아내기 위한 `설명 가능성 연구(eXplainable AI, XAI)`도 계속되고 있다. LLM은 복잡한 신경망 구조 때문에 그간 블랙박스 모델로 간주되어 결정 과정을 이해하기 쉽지 않았다. XAI는 이러한 불투명성을 해소하고 모델의 신뢰성과 투명성을 높이는 데 중요한 역할을 하는 연구다.

#### 일상생활의 필수품이 된 LLM

- 저자도 이 책을 집필하며 LLM의 도움을 많이 받았다.
  - 풍부한 표현이 필요할 때는 클로드를, 논리적인 전개가 중요할 때는 주로 챗GPT를, 정확한 표현이 필요한 부분에는 제미나이를 주로 사용했다고 한다.

#### 기술을 거부하던 러다이트 운동

- 기술은 끊임없이 발전하지만 오히려 이로 인해 더욱 많은 새로운 일자리를 창출해낸다.
- 반면 이제 끊임없이 공부해야 하는 시대가 찾아왔다. 이른바 평생 교육이 당연한 일이 될 것.
- 스스로 필요해서 하는 공부는 재밌다. 중요한 것은 국영수, 경쟁, 재미없는 과목도 외우다시피 하는 것이 아니라 공부하는 그 자체다.

#### 천재란 어떤 사람인가? 창의성이란 무엇인가?

- 현대 사회에 천재라는 개념은 인류가 수천 년간 이룩한 문명과 지식을 잘 흡수해서 적재적소에 활용하는 능력이다.
- 창의성의 시작은 아는 것부터 공부하는 것이고 공부가 끝나야 비로소 감각이 생긴다. 아무것도 모르는데 어느 날 갑자기 떠오르는 게 결코 창의성이 아니다.
  - 네이버의 유명한 초록색 검색창을 디자인하고, 카카오 대표를 역임한 바 있는 조수용 대표는 창의성의 원천은 '보고 외우는 것'이라고 자신있게 강조한다.
- 배움에 대한 내용을 다룬 <학습의 재발견> 이라는 책에서도 창의성을 '전문 지식의 확장'으로 정의했다. 즉, 창의적 성공에서 가장 중요한 요소는 '축적된 지식'이다.

#### LLM의 미래는 어떻게 될까?

- 앞으로 에이전트 기반의 서비스가 다양하게 출시될 것이며, 이와 함께 LLM의 성능은 더욱 고도화될 것이다.
- 스케일링 법칙으로 모델의 크기는 점점 더 커지고 이를 효율적으로 처리하는 기술도 다양하게 등장할 것이다. 학습 효율을 높이면서도 전기를 훨씬 더 적게 먹는 최적화된 반도체도 등장할 것이다.
- 기업용 `소형 언어 모델(Small Language Model, SLM)`도 많이 등장할 것이다.
  - 특히 챗GPT 같은 공개 서비스를 사용하기 어려운 기업 외에도 군사, 의료, 정보기관 같은 보안이 필요한 특수 분야에서는 소형 언어 모델을 기반으로 다양한 온디바이스 AI가 대중화될 것이다.
  - 스마트폰에서도 직접 다양한 소형 언어 모델을 구동해 개인정보 유출 걱정 없이 LLM을 활용할 수 있게 될 것이다.

> `멀티모달(Multimodal)`  
> 여러 가지 방식(Mode)이나 유형을 동시에 활용하는 것. 기존 텍스트만 이해하던 것은 유니모달(Unimodal)이라 한다. 멀티모달은 텍스트로 설명할 수 없는 사진이나 영상까지도 동시에 처리할 수 있어 활용 범위가 크게 확장된다.

- 얼마 전 애플은 `애플 인텔리전스(Apple Intelligence)` 를 발표하며 LLM의 스마트폰 통합을 본격화했다.
- 인공지능의 목적은 인간을 완전히 대체하기보다 보완하는 데 있다. 잊지 말아야 할 것은 최종 결정은 항상 인간이 내린다는 점이다.
  - 인공지능을 도구로 활용해야지, 인공지능에 모든 것을 의존해서는 안 된다.
- 기술이 우리 삶을 변화시키는 것은 분명하지만, 그 변화를 어떤 방향으로 설계하고 통제할지는 결국 인간의 몫이다.

> 인공지능은 당신을 대체하지 않습니다.  
> 인공지능을 이해하고 활용하는 사람이 당신을 대체할 뿐입니다.

---

#### Comment

- (p.356-357) 최근 검색 엔진들에 원박스 기능이 도입되면서 편리함을 느끼고 있었는데, 콘텐츠 제작자의 관점에서는 생각해보지 못 했다.
- (p.365) 찾아보니 옵트아웃 설정 신청 방식에 통일된 단일 제도는 없고, 방식도 다양한데 각각의 방식이 모두 굉장히 번거롭다.
