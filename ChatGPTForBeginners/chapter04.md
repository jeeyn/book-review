## 제4장 초거대 모델 최적화 기술

#### 초거대 모델을 여러 GPU에 담는 법

- 엔비디아의 최상급 GPU인 H1000은 한 장에 약 6,000만원
- 크기가 175B GPT-3 모델을 사용하려면 매개변수 하나가 2바이트를 차지한다고 했을 때 약 350GB의 메모리가 필요하다.
  - 토큰 하나를 생성하려면 이 350GB 메모리 전체를 매번 읽어들여야 한다.
- CPU와 달리, GPU에는 `HBM(High Bandwidth Memory)` 이라는 매우 빠른 초고속 메모리가 별도로 탑재되어 성능을 극대화한다.
  - SK 하이닉스가 엔비디아에 독점적으로 납품 중
- 큰 모델을 여러 장의 GPU에 나눠 담는 방법에는 다음과 같은 방식이 있다.
  1. `텐서 병렬화(Tensor Parallelism)` : 모델을 식빵 자르듯이 필요한 만큼 쪼개어 분할하는 방식
  2. `파이프라인 병렬화(Pipeline Parallelism)` : 텐서 병렬화가 모델 자체를 직접 쪼갰다면, 파이프라인 병렬화는 모델은 건드리지 않고 처리되는 순서를 분할하는 방식
     - 이 방식은 순서를 잘게 쪼개어 여러 장에서 순차적으로 처리하면 되므로 모델이 아무리 커도 문제가 없어 비교적 쉽게 분산할 수 있다.
     - 반면 순차적으로 처리하기 때문에 뒤에 있는 GPU는 앞의 GPU가 처리를 끝낼 때까지 계속 대기하므로 비효율적

#### 매개변수는 몇 바이트일까요?

- 매개변수는 주로 -1과 1 사이의 실수(Real Number)
- 컴퓨터는 복잡한 실수를 잘 표현할 수 있도록 `부동소수점(Floating Point)` 이라는 방식을 사용한다.
  - 1985년에 국제 표준으로 지정
- 부동소수점은 과학적 표기법과 마찬가지로 지수부와 가수부가 있다.
  - 지수부는 표현범위를, 가수부는 유효숫자를 나타내는 것도 완전히 동일
  - 대신 2진법을 사용하고, 음수 여부를 구분하기 위한 부호 비트가 있다는 점이 다르다.
- 1985년에 표준이 제정될 당시 부동소수점의 기본값은 32비트(4바이트)였다. 32비트를 사용하기 때문에 `float32` 라고도 부른다.
  - 한 가지 치명적인 문제는 4바이트가 너무 크다는 것
- 그래서 보통은 이걸 절반으로 줄여 16비트(2바이트)만 사용한다.
  - 당연히 표헌 범위가 너무 제한적이고, 수를 정교하게 표현하기는 어렵다.
  - 때문에 정밀도를 낮췄다 하여 `반정밀도(Half-Precision)` 라 부른다. 또는 16비트를 사용하므로 `float16` 이라고도 한다.
- 딥러닝에서는 float16을 사용하기가 어렵다. 구글은 이 문제를 해결하기 위해 지수부를 float32와 동일하게 8비트로 유지하고, 가수부는 7비트로 확 줄였다. 이 자료형의 이름은 `bfloat16`
  - 가수부가 크면 더 정교한 값을 찾을 수 있지만, 그보다는 정확도가 떨어지더라도 지수부를 좀 더 키워서 표현범위를 보장하는 게 딥러닝에서는 훨씬 중요하다는 것
  - 구글 브레인에서 개발했다고 하여 앞에 b를 붙였다.
- 현재 출시되는 엔비디아의 최신형 GPU에는 bfloat16 지원이 모두 기본으로 탑재되어 있다. 이제는 딥러닝 연구 시 대부분 bfloat16을 사용한다. 실상 딥러닝을 위한 기본 자료형이라 할 수 있다.
  - 매개변수 2바이트가 기본이라 한 것은 이 자료형을 사용하는 경우를 지칭한 것

#### 양자화, 초거대 모델을 작게 만드는 비밀

- 매개변수당 용량을 2바이트에서 1바이트로 줄이면서도 LLM의 품질을 유지할 수 있는 적절한 비율을 찾는 게 중요

> `양자화(Quantization)`  
> 연속적인 실수값(보통 부동소수점)을 더 적은 비트 수의 이산적인 값(정수형)으로 근사하여 표현하는 것. 원래 넓은 공간에 여유롭게 분포되어 있던 값을 자료형을 줄여서 훨씬 더 좁은 공간에 촘촘히 배치하는 것이 양자화 과정이다.

- 양자화를 진행하고 나면 메모리를 차지하는 공간이 줄어들고 연산 속도도 더 빨라지는 이점이 있다. 그러나, 정보의 손실이 있다는 단점도 있다.
  - 예를 들어, 최댓값이 유난히 크고 나머지 값들이 촘촘하게 분포하는 경우 최대값으로 인해 나머지 값들의 하나의 값으로 수렴된다. 이럴 때는 유난히 큰 특이값을 제거하는 식으로 양자화를 진행하여 모델의 성능 저하를 방지한다.

#### 플래시 어텐션, 빛처럼 빠른 속도의 비밀

- GPT-3가 토큰 하나를 생성하기 위해서는 어텐션을 96번씩 동시에 계산하면서 이 과정을 96회 반복한다. 즉, 하나의 토큰 생성을 위해 어텐션을 총 9,216번 계산한다.
- 이렇게 많은 연산량을 줄여보고자 등장한 여러 기법 중 가장 유명한 기법은 스탠퍼드에서 박사 과정을 밟던 `트리 다오`가 제안한 `플래시 어텐션(Flash Attention)` 이다.

> SRAM(Static Random Access Memory)  
> GPU 안 쪽에 내장되어 있어 엄청 빠른 메모리. HBM보다도 6배 가까이 더 많은 초당 19TB의 데이터를 전송할 수 있다. 대신 구조가 복잡하고 용량이 적으며 가격이 비싸다.

- 플래시 어텐션의 기본 동작 원리는 HBM보다 대역폭이 큰 SRAM으로 꼭 필요한 데이터를 조금만 가져와 계산하면서 훨씬 빠르게 처리하는 것
  - 플래시 어텐션은 데이터를 한꺼번에 읽어들이고 계산 중에 중간값은 SRAM에 저장하는 형태로 처리하면서 속도를 높인다. 여러 차례 HBM과 주고받는 대신, 한 번만 받아오고 그 다음부터는 SRAM을 이용해 계산하는 형태로 계산 방식을 변형한 것이다.
- 플래시 어텐션을 적용한 결과, 최대 10배까지 속도를 높일 수 있게 되었다. 지금은 LLM 학습, 추론할 때 사실상 플래시 어텐션을 필수로 활용한다.

#### KV캐시, 더욱 더 빠르게

> 캐싱(caching)  
> 자주 사용되는 데이터의 복사본을 빠른 임시 저장소(캐시)에 보관했다가, 다음에 같은 데이터 요청이 있을 때 원본 대신 캐시에서 가져와 성능을 향상시키고 시스템 부하를 줄이는 기술

- LLM이 토큰을 생성하는 방식은 캐싱과 관련이 깊다. 문장을 만들 때 문장이 점점 길어져도 이전 토큰에 대한 어텐션 결과는 항상 동일하기 때문 (마스크드 어텐션으로 진행되므로)
- 같은 값으로 계산을 반복하기 때문에 캐시를 응용할 수 있다. 키와 값에서 현재 토큰에 대한 값만 계산하고 나머지는 모두 캐시에서 꺼내온다.
  - 이처럼 키(K)와 값(V)은 캐시를 활용한다고 하여 `KV캐시(KV Cache)` 라고 부른다. KV캐시를 활용하면 불필요한 계산은 하지 않으므로 계산량을 획기적으로 줄일 수 있다.

#### 품질 좋은 문장을 생성하는 비밀 옵션

- 일부 연구자들은 LLM을 `확률적 앵무새(Stochastic Parrot)` 라고 비판하기도 한다. LLM이 언어의 의미는 전혀 이해하지 못한 채 단순히 학습 데이터를 바탕으로 확률적 패턴에 따라 언어를 조합할 뿐이라는 것
- 모델의 반응을 제한하거나 영향을 주기 위해 조정할 수 있는 값 중 `Top K` 라는 값이 있다. '상위 K개'라는 뜻
  - 예를 들어 Top K = 10이면 상위 10개의 토큰만을 대상으로 한다.
- `Top P` 는 특정 확률 이내를 의미한다. 예를 들어 Top K = 80%라면 확률이 높은 순으로 누적하여 전체 합이 80%가 될 때까지의 토큰만을 고려한다. (나머지 하위 20%는 보지 않음)
- Top K와 Top P만 잘 활용해도 품질이 나쁜 토큰이 추출되는 일은 거의 없다.
- 변별력을 조정하기 위한 옵션으로는 `온도(Temperature)` 라는 값이 있다.
  - 온도를 높이면 확률이 서로 비슷하게 평준화되고, 온도를 낮추면 변별력이 높아진다.
  - 즉, 온도를 높이면 좀 더 다양한 답변을 할 수 있고, 낮추면 좀 더 일정한 답변을 하게 된다.
- 동일한 토큰에 대해서는 페널티를 부여해 출현 빈도를 줄일 수 있다.
- 생성할 수 있는 문장의 최대 길이를 제한하는 것도 중요하다. LLM에는 강제로 토큰 생성을 멈추는 특수한 토큰이 포함되어 있다. 하지만 비정상적으로 동작해 끝까지 종료 토큰이 나오지 않는 경우, 최대 길이를 명시적으로 지정해 해당 글자 수까지 생성하고 강제로 멈추도록 할 수 있다.

#### 수천 장의 GPU에 분산 학습하는 법

> `추론(Inference)` : 토큰을 생성하는 단계  
> `학습(Training)` : 추론할 수 있는 LLM을 만드는 것

- LLM을 학습하는 과정은 여러 장의 GPU를 한꺼번에 사용한다는 것을 의미한다.
- 모델을 1장 또는 여러 장에 나눠서 보관했을 때 이를 하나의 그룹으로 두고 데이터를 쪼개서 학습하면 여러 장의 GPU에서도 분산해서 학습할 수 있다.
- 데이터셋에서 정답은 다음에 나올 토큰이다. 다음 토큰과 일치한다면 손실이 없는 것이고, 일치하지 않는다면 손실값을 부여해서 정답을 찾도록 모델을 조정한다.
  - 손실값을 각각의 GPU 그룹이 별도로 계산한 다음에는 손실값을 모두 동기화해서 평균을 구하고, 평균만큼 모든 GPU가 손실값을 반영한다. 그리고 다시 다음 데이터를 학습하기를 반복한다.
- 이 같은 구조로, 이전 문장을 기준으로 다음 토큰이 나오도록 데이터를 분산해서 여러 장의 GPU에 나눠 락습하는 것이 언어 모델 사전 학습의 기본 원리다.
- RM이 필요 없고, 강화학습도 사용하지 않는 방식을 고민하여 나온 방법 중 가장 단순하면서 효과가 좋았던 방식이 스탠퍼드 대학교 연구팀에서 제안한 `DPO(Direct Preference Optimization)` 이다.
  - DPO는 PPO 같은 정책 기반의 강화학습 알고리즘이 아닌, 인간의 선호도를 직접 반영하는 최적화 방법이다. 이 방식을 사용하면 RM → PPO로 이어지는 절차는 모두 생략한 채 단순히 기존 SFT 모델을 활용해 DPO 방식을 적용하기만 하면 된다.
  - DPO는 두 개의 응답 중 어느 것을 더 선호하는지에 대한 비교 데이터를 사용하여 선호하는 응답에 확률을 더 높이는 방식으로 모델을 학습한다.
- DPO 방식 학습 모델은 PPO 방식과 비교해 성능에 큰 차이가 없다. 최근 오픈소스 LLM은 DPO만 적용하는 경우가 늘고 있다.

#### 과연 좋은 모델이란?

- 생성 모델은 평가가 어렵다. 생성된 문장이 얼마나 좋은 모델인지 알 수 어렵고, 애초에 '좋다'라는 기준이 무엇인지도 불분명하기 때문
- 자연어 처리 이전에 음성인식에도 비슷한 문제가 있었다. 음성을 텍스트로 정확하게 받아썼는지 평가하기 위한 지표로 1977년 `퍼플렉시티(Perplextity)` 라는 지표를 고안했다.
  - 이 평가 지표는 음성인식뿐 아니라 기계번역, 텍스트 요약 같은 자연어 처리에도 사용되며, LLM에서 언어 생성을 평가하는데에도 동일하게 사용한다.
- 퍼플렉시티는 정보 이론의 불확실성에 기반한다. 퍼플렉시티가 높으면 불확실하고, 퍼플렉시티가 낮으면 확실하다는 의미이다.
  - 즉, 퍼플렉시티 값이 낮을수록 모델의 성능이 좋다고 평가하며, 퍼플렉시티가 낮을수록 좋은 LLM이라고 할 수 있다.
- 동일한 이름의 AI 서비스는 복잡하거나 어려운 질문이라도 사용자에게 정확하고 유익한 답변을 제공하고자 하는 회사의 목표를 반영하여 명명했다고 한다.
- 퍼플렉시티는 빠르고 간단하게 성능을 측정하는 유용한 방법이지만 꽤 오래 전에 고안된 지표인 만큼 한계도 분명하다.
  - 모델이 문법적으로 올바른 문장을 생성하는지 여부 등은 전혀 평가하지 않고, 오로지 확률적인 예측 성능만을 측정한다.
  - 따라서 최근에는 퍼플렉시티를 간이 지표로만 활용한다.
- 기술이 발전하면서 다양한 평가셋이 늘어났고, 그 중 대표적인 방식이 2020년에 UC버클리 연구진이 공개한 사지선다형 문제로 구성된 MMLU 라는 평가셋을 활용하는 것이다.
  - 과학, 기술, 공학, 수학, 인문학, 사회과학, 법률, 윤리 등 57개 과목에 걸쳐 1만 4,000여 개의 사지선다형 평가 문제로 구성되어 있다.
- 동일한 방식으로, 연세대 연구진이 만든 한국어 평가셋 KMMLU도 있다. 이 평가셋은 단순히 영문 평가셋을 번역한 게 아니라 애초에 한국어로 만든 시험 문제지에서 문제를 추출해서 구성했다.
  - 그래서 어색한 번역체나 미국 문화를 묻는 문제가 아니라 45개 과목에 걸쳐 실제 우리나라 문화에 맞는 3만 5,000여 개의 평가 문제로 구성되어 있다.
- 이 외에도 오픈AI에서 만든 프로그래밍 코드 생성 능력 평가를 위한 휴먼이밸(HumanEval)과 8,000개가 넘는 초등학교 수학 문제로 구성된 GSM8K, MMLU를 만들었던 UC버클리 연구진들이 수학 문제 해결 능력을 전문적으로 평가하기 위해 만든 MATH(Mathematics Aptitude Test of Heuristics) 평가셋 등이 공개되었다.
- 다양한 평가셋을 모두 종합적으로 판단하여 LLM의 성능을 최종 평가하는 것이 가장 좋은 방법이다.

---

#### Comment

- 두 달만에 다시 읽기 시작. 이 장에서 3장에서 등장한 개념들에서 이어지는 내용이 꽤 나오는데 많이 까먹었다;
