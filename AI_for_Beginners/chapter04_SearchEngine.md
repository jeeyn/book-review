## 제4장 검색엔진: 구글이 세상을 검색하는 법

```
< Discussion >
현재 검색엔진 랭킹 알고리즘의 성능이 꽤나 훌륭하다지만, 개인적인 경험에 비추어볼 때, 검색 결과에서 상위에 노출되는 문서가 항상 만족스러웠던 것 같지는 않습니다.

책에서 제시된 요소들 외에 좋은 문서를 판단하기 위해서는 랭킹 알고리즘에 어떤 기준이 더 고려되면 좋을까요?
```

#### 검색엔진 등장하다

- 검색 서비스는 국가를 가리지 않고 가장 인기 있는 1등 인터넷 서비스다.
  - ex. 한국 `네이버`, 중국 `바이두`, 일본 `야후! 재팬`, 러시아 `얀덱스`, 그 외 `구글`
- 인터넷 초창기, 웹이 서서히 인기를 얻어갈 무렵인 1990년대에는 디렉토리 서비스\*가 인터넷의 첫 관문이었다.
  > \* `디렉토리 서비스`<br/>
  > 인터넷 사이트를 주제별로 일목요연하게 정리한 서비스. 초기에는 사람이 직접 주제별로 정리했다.
- 사람들은 편집된 디렉토리보다는 검색엔진에 의존했고, 그 결과 구글은 세계 최고의 검색엔진이자 2024년 상반기 기준 시가총액 세계 4위 기업으로 성장했다.

#### 엄청난 돈을 벌어들이다

- 검색엔진이 시장의 흐름을 주도하면서 광고 방식도 변화했다.
  - 전통 미디어와 같이 사이트에 배너를 노출하고 노출 횟수에 따라 가격을 책정하는 방식 → 쿼리에 적합한 광고를 매번 다르게 보여주는 타깃 마케팅을 진행하고, 사용자 피드백을 기반으로 광고료를 산정하는 `CPC(Cost Per Click)` 방식
- 검색엔진의 수익 모델이자, 구글의 대표적인 수익 모델은 다음과 같다.
  - 대표적인 사용자의 피드백은 클릭이다. 사용자의 클릭에 따라 광고료를 매기기 때문에 클릭할 가능성을 높이는 것이 핵심이다. 이를 위해 시스템이 더 정교해졌다.
  - 검색 광고는 경매 방식으로 판매한다. 단순히 경매 단가가 높다고 무작정 광고가 노출되는 게 아니라 클릭률을 함께 높이는 게 핵심이다. 때문에 클릭율 예측 알고리즘은 입찰 광고 최적화에 매우 중요한 역할을 한다.

#### 엄청난 문서를 수집하다

- 검색엔진이 인터넷에 있는 문서를 수집하여 검색에 적합하도록 보관하고 있는 것을 `색인(Index)`이라고 한다.
- 구글은 2020년 이후 300조 개가 훨씬 넘는 문서를 색인하고 있을 것으로 추정된다. 이를 위해 엄청난 양의 문서를 고가의 컴퓨터 몇 대에 저장하는 게 아니라 저렴한 컴퓨터 수백, 수천 대에 나눠서 저장하는 `구글 파일 시스템(GFS; Google File System)`이라는 효율적인 분산 파일 시스템을 만들었다.
  - 이 방식은 초기 빅데이터 플랫폼의 원형이 되어 나아가 인공지능의 시대가 열리는 계기가 된다.
- 웹은 링크로 연결된 거미줄(Web)과 유사한 형태를 띠고 있기 때문에 웹사이트에서 정보를 수집하는 로봇을 스파이더(Spider)라고 부른다. 또는 웹 문서를 갈고리처럼 긁어온다고 해서 `크롤러(Crawler)`라고도 부른다.
  - 크롤러는 웹 문서를 방문할 때마다 특수한 데이터베이스인 '색인'에 정보를 추가한다.
  - 우선, 크롤러에게는 방문할 사이트 목록이 필요하다. 크롤러가 해당 URL을 방문하면 사이트 내 웹 문서의 모든 링크를 식별하고 방문할 URL을 큐라는 목록에 계속해서 추가한다.
  - 그러면서 크롤러는 방문한 웹 문서에서 필요한 내용을 추출하여 저장하는 작업을 병행한다. 크롤러는 사람만큼이나 웹 문서의 내용을 잘 이해해야 하기 때문에 매우 정교해야 한다.
  - 스케줄러는 한 번 방문한 사이트는 일정 시간 재방문하지 않는 정책을 관리한다.
    > `선택 정책 연구`<br/>
    > 방대한 웹 문서 URL 중에 어떤 페이지를 먼저 방문할 것인지에 대한 연구 주제. 우리나라의 조정후 박사가 이 분야로 유명하며, 초창기 구글의 크롤러 구현에 많은 기여를 했다.

#### 랭킹, 수십 조 가치의 줄 세우기 기술

> `랭킹`<br/>
> 어떤 문서를 가장 먼저 노출할지 결정하는 알고리즘

- 서로 다른 성질을 가진 대상을 정량적으로 비교하기 위해 다양한 특성을 모두 점수로 치환하고 점수의 총점으로 순서를 정한다.
- 검색엔진은 문서의 저마다 다른 특성을 종합적으로 고려하여 문서의 점수를 정한다. 구글의 경우, 약 200여 가지의 랭킹 조건을 이용한다고 알려졌다.

#### 최신 문서를 찾아서

- 일반적으로 최신 문서일수록 랭킹 점수 경쟁이 치열하다. 반면 오래된 문서들은 비교적 점수 차이가 적다.
  - 1주일 이내에 발행된 문서끼리는 하루 차이로도 점수 차이가 많이 나지만, 2년 전에 발행된 문서는 3년 전 문서와 별 차이가 없다.

#### 품질 좋은 문서를 찾아서

- 품질이 좋은 문서란 검색 쿼리에 관계없이 항상 좋은 문서를 말한다.
  - ex. 짧은 문서보다는 긴 문서, 권위 있는 사이트에 실린 문서 등
- 문서의 품질을 평가하기 위해 '에르되시 수'와 '논문 인용 횟수' 컨셉을 조합하여 활용할 수 있다.

#### 페이지 랭크, 구글의 역사가 탄생하다.

> `페이지 랭크(Page Rank)`<br/>
> 유명한 사이트가 많이 가리킬 수록 점수가 올라가고, 권위있는 사이트일 수록 가중치를 높여 문서 품질을 평가하는 알고리즘. 구글의 창업자 세르게이 브린과, 래리 페이지가 스탠퍼드에서 박사 과정 중 고안했다.

- 페이지 랭크 알고리즘은 횟수와 권위를 환산한 값에 댐핑 팩터를 반영한다. 댐핑 팩터란 사용자들이 싫증을 낼 확률을 반영한 값이다.
  - 사용자가 링크를 따라가 웹 문서를 읽다가 흥미를 잃고 해당 문서에서 벗어낫 확률이 15% 정도라면, 댐핑 팩터는 이 값을 반영하여 0.85가 된다.
  - 페이지 랭크 논문에서 정한 댐핑 팩터의 기본값도 0.85 다.
- 페이지 랭크의 적용으로 검색엔진에서 스팸이 사라지기 시작했고, 높은 검색 품질을 무기로 구글은 검색 시장을 점령했다.
  - 2024년 상반기 기준 구글의 전 세계 검색 시장 점유율은 91%가 넘는다.

#### 쿼리에 딱 맞는 문서 찾는 법

- 쿼리와 그에 따른 문서가 얼마나 유사한지는 사실상 검색엔진의 핵심이며, 이는 유사도 점수를 통해 판단한다.
- 우선, 사용자가 입력한 쿼리가 제목, 본문 등 문서 어디쯤에 위치하는지가 중요하다. 아무래도 제목이 훨씬 더 중요하므로 제목에 위치하는 경우 더 높은 점수를 부여한다.
- 또한 순서대로 매칭되었는지도 중요하다. 문서에 쿼리의 단어가 차례대로 표시되어 있다면 더 유사하다고 볼 수 있다. 이를 검색 분야에서 `근접도(Proximity)`라고 하며, 단어와 단어 사이의 간격이 좁을수록 더 유사한 문서라고 판단하고 높은 점수를 부여한다.

#### TF-IDF 그리고 마법 같은 BM25

- 근접도만으로도 유사한 문서를 판별할 수 있지만, `TF-IDF`는 더 훌륭한 유사도 알고리즘이다. 이 알고리즘은 정보 검색 분야에서 가장 중요한 발명품이다.
  > $$TF-IDF 점수 = TF 점수 \times IDF 점수 = 단어 출현 빈도 \times \frac{1}{문서 출현 빈도}$$
  - TF(Term Frequency) : 단어의 출현 빈도
  - IDF(Inverse Document Frequency) : 문서 출현 빈도의 역수. IDF는 다른 문서에 많이 출현할수록 작은 값이 된다.
  - 즉, 해당 문서에 많이 출현할수록, 다른 문서에는 적게 출현할수록 TF-IDF 점수가 커진다.
- 검색과 추천 시스템의 83%가 TF-IDF를 사용한다.
- TF-IDF를 기반으로 하는 점수 계산 방식 중 가장 성능이 좋다고 알려진 방식으로 `BM25(Best Matching 25)`가 있다.
  - 이 방식은 구글, 네이버, 다음 등 사실상 국내외 모든 검색엔진이 채택한 유사도 계산 방식이다.
  - BM25는 TF-IDF와 동일한 원리\*에 몇 가지 최적화를 덧붙여 훨씬 더 합리적인 점수를 유도한다<br/>
    > \* 다른 문서에 등장하지 않는 단어가 해당 문서에 많이 포함되어 있을 수록 높은 점수를 얻는 원리
  - 먼저, BM25는 TF 점수가 무한대로 증가하지 않고 특정 점수 이상을 넘지 않는다.
  - 또한 BM25는 문서 길이를 고려한다. TF-IDF는 문서 길이를 고려하지 않기 때문에 긴 문서가 무조건 유리하지만 BM25는 현재 문서 길이와 전체의 평균 길이를 비교하면서 가중치를 조절하기 때문에 같은 조건에서는 오히려 짧은 문서가 좀 더 유리하다.
  - BM25 수식에는 랭킹을 모델링하는 개발자가 최종 점수 분포를 정하기 위해 임의로 설정하는 k1, b 두 개 값(매개변수)가 있다.
    - 기본값으로는 k1 = 1.5, b = 0.75를 사용한다.

#### A/B 테스트, 검색 개선을 확인하는 법

- 검색엔진은 최신, 품질, 유사도에 더해 다른 여러 조건에 해당하는 점수를 적절한 비율로 합산하여 최종 점수를 계산한다.
- 이 결과가 적합한지, 즉 많은 사람들이 실제로 좋아할 결과인지를 확인하는 방법으로 `A/B 테스트`가 있다.
- A/B 테스트의 시초는 과학 분야에서 사용했던 `무작위 대조 시험`\*이다. A/B 테스트는 이 무작위 대조 시험을 온라인에서 구현한 것이다.
  > \* `무작위 대조 시험(Randomized Controlled Trial)`<br/>
  > 말 그대로 피실험자를 2개 이상의 그룹에 무작위로 할당하여, 한 그룹(실험 그룹)은 개선된 조건으로 실험을 수행하고, 다른 그룹(대조 그룹)은 기본 조건으로 실험하여 그 결과를 비교하는 방식
- 첫 A/B 테스트는 2000년대 초반 구글이 사용자를 무작위로 나눈 두 집단에 서로 다른 검색 결과를 보여준 실험이었다.
- 데이터 분석 분야에서 인과관계를 밝히는 일은 무척 어려운데, 인과관계를 직접 밝히는 가장 좋은 방법인 직접 시험, 즉 A/B 테스트를 통해 해결책을 제시했다.
  - 이후 A/B 테스트는 데이터를 근거로 서비스를 개선하는 좋은 수단이 되었다. A/B 테스트는 '데이터 기반 의사 결정'을 하는 데 가장 핵심적인 역할을 하는 것이다.
  - 구글은 매년 1만회 이상 A/B 테스트를 진행하는 것으로 알려져 있다.
- 아무리 수학적으로 우아해 보이는 모델이라도 사용자들은 좋아하지 않을 수 있다. 따라서 사용자의 반응을 미리 실험해보는 A/B 테스트가 반드시 필요하다.
- A/B 테스트는 랭킹 알고리즘이 개선되었는지 효과를 효율적으로 측정하는 방식이기도 하다.

#### 검색엔진 최적화, 창과 방패의 싸움

- `검색엔진 최적화(SEO; Search Engine Optimization`를 시도하는 업체들은 여러가지 실험을 해보며 랭킹을 높이기 위해 끊임없이 도전한다.
  - 구글에는 200여 가지의 랭킹 조건이 있는데, 검색엔진 최적화는 이들 조건 사이에서 빈틈을 찾아 랭킹을 올리기 위해 끊임없이 노력한다.
- 반면 검색엔진 업체들은 쉽게 랭킹을 올릴 수 없도록, 품질이 좋은 문서만 랭킹에 오를 수 있도록 방어 로직(알고리즘)을 개선하고 진화시킨다.

#### 점점 더 똑똑해지는 구글 검색의 진화

- 사람들은 점점 더 똑똑한 검색엔진을 원한다. 이제는 쿼리의 맥락을 파악하여 적절한 문서를 제시해주는 수준에 이르렀다.
  - ex. '소니에서 개발한 회색 콘솔' 검색 → 검색엔진은 '플레이스테이션'을 포함한 문서를 정답으로 제시
- 이렇게 작동하기 위해 딥러닝이 문장의 의미를 이해하고 이에 맞는 정답을 찾아주는 역할을 한다. 딥러닝은 비슷한 의미를 지닌 단어를 비슷한 숫자로 표현할 수 있고, 따라서 유사한 의미를 지닌 단어로 판별해낼 수 있다.
- 딥러닝은 검색의 결과뿐만 아니라 검색과 관련된 다양한 분야에서도 활용된다.
  - ex. 오타 교정, 번역, 제안 등
- 2021년 상반기, 구글은 복잡한 질문에 답하기 위해 딥러닝을 결합한 새로운 기술인 `MUM(Multitask Unified Model)`을 발표했다.

---

#### Comment

- (p.169-170) 랭킹 알고리즘 구현 및 고도화 파트에서 구글의 업무 RnR이 어떻게 구성되는지 궁금했다. 책에 예시로 나열된 랭킹 조건들 중 하나만 해도 보통 일이 아닐 듯 한데.
- (p.197-198) 검색엔진 최적화가 잘 되었는지는 어떻게 판단하지?
